{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('/home/sheida.rahnamai/GIT/HDN/')\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "# from lib.dataloader import CustomTestDataset\n",
    "from boilerplate.dataloader import CustomTestDataset\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from boilerplate import boilerplate\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch.nn.functional import unfold\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "dist_metric = ['cosine']\n",
    "\n",
    "num_clusters = 4\n",
    "patch_size = (64,64)\n",
    "mask_size = 5\n",
    "label_size = 5\n",
    "n_channel = 32\n",
    "hierarchy_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image loaded from path:\n",
      "/group/jug/Sheida/pancreatic beta cells/download/high_c4/high_c4_source.tif\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/group/jug/Sheida/pancreatic beta cells/download/\"\n",
    "\n",
    "One_test_image = ['high_c4']\n",
    "\n",
    "# Load test image\n",
    "test_img_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_source.tif\")\n",
    "test_images = tiff.imread(test_img_path)\n",
    "\n",
    "# Print loaded test images paths\n",
    "print(\"Test image loaded from path:\")\n",
    "print(test_img_path)\n",
    "\n",
    "# Load test ground truth images\n",
    "test_gt_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_gt.tif\")\n",
    "test_ground_truth_image = tiff.imread(test_gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_pixels(ground_truth):\n",
    "    # Get unique labels and their counts\n",
    "    unique_labels, counts = np.unique(ground_truth, return_counts=True)\n",
    "    \n",
    "    # Create a dictionary to store label-wise pixel counts\n",
    "    label_pixel_counts = dict(zip(unique_labels, counts))\n",
    "    \n",
    "    return label_pixel_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-wise pixel counts:{-1: 409001638, 0: 107710351, 1: 25910981, 2: 36936035, 3: 23104175}\n"
     ]
    }
   ],
   "source": [
    "label_pixel_counts = count_label_pixels(test_ground_truth_image)\n",
    "print(f\"Label-wise pixel counts:{label_pixel_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_pixels_within_range(ground_truth, labels, pixels_per_class, x_range, y_range, z_range):\n",
    "    selected_pixels = {}\n",
    "\n",
    "    for label in labels:\n",
    "        # Get the coordinates where ground truth equals the label\n",
    "        coords = np.argwhere(ground_truth == label)\n",
    "        \n",
    "        # Filter coordinates based on the specified range\n",
    "        x_in_range = (coords[:, 2] >= x_range[0]) & (coords[:, 2] <= x_range[1])\n",
    "        y_in_range = (coords[:, 1] >= y_range[0]) & (coords[:, 1] <= y_range[1])\n",
    "        z_in_range = (coords[:, 0] >= z_range[0]) & (coords[:, 0] <= z_range[1])\n",
    "        \n",
    "        # Keep only the coordinates that satisfy all range conditions\n",
    "        filtered_coords = coords[z_in_range & y_in_range & x_in_range]\n",
    "        \n",
    "        # Check if there are enough pixels for the current label after filtering\n",
    "        if len(filtered_coords) < pixels_per_class:\n",
    "            raise ValueError(f\"Not enough pixels for label {label} within the specified range. Found {len(filtered_coords)}, required {pixels_per_class}\")\n",
    "        \n",
    "        # Randomly select pixels_per_class coordinates from filtered_coords\n",
    "        chosen_indices = np.random.choice(len(filtered_coords), pixels_per_class, replace=False)\n",
    "        chosen_coords = filtered_coords[chosen_indices]\n",
    "        \n",
    "        # Store selected coordinates for the label\n",
    "        selected_pixels[label] = chosen_coords\n",
    "\n",
    "    return selected_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_of_interest = [0, 1, 2, 3]\n",
    "z, y, x = test_images.shape\n",
    "x_range = (32, x - 32)\n",
    "y_range = (32, y - 32)\n",
    "z_range = (0, z - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pixel_coords = select_random_pixels_within_range(test_ground_truth_image, labels_of_interest, pixels_per_class=256, x_range=x_range, y_range=y_range, z_range=z_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [[ 753  217  399]\n",
      " [ 588  418  440]\n",
      " [ 446   76  810]\n",
      " [ 344  307  929]\n",
      " [ 574  228  687]\n",
      " [ 688  442  985]\n",
      " [ 848  394  464]\n",
      " [ 575  194  302]\n",
      " [ 659  308  186]\n",
      " [ 883  404  615]\n",
      " [ 314  423  471]\n",
      " [ 374   99  670]\n",
      " [ 839  315  877]\n",
      " [ 714  286   99]\n",
      " [ 676  102  617]\n",
      " [ 550  417  389]\n",
      " [ 760  330  623]\n",
      " [ 606  436  479]\n",
      " [ 654  173  720]\n",
      " [ 315  137  447]\n",
      " [ 372  247  897]\n",
      " [ 686  218  731]\n",
      " [ 833  285   97]\n",
      " [ 403  151  414]\n",
      " [ 805  221  570]\n",
      " [ 481  500  541]\n",
      " [ 525  167  625]\n",
      " [ 835  394  559]\n",
      " [ 196  228  897]\n",
      " [ 737  300  730]\n",
      " [ 438  191  944]\n",
      " [ 589  363  427]\n",
      " [ 490  244  887]\n",
      " [ 363  255  241]\n",
      " [ 651  435  277]\n",
      " [ 796  203  277]\n",
      " [ 785  194  441]\n",
      " [ 208  155 1011]\n",
      " [ 472  175  630]\n",
      " [ 339  232  470]\n",
      " [ 429  204  954]\n",
      " [ 893  390  407]\n",
      " [ 756  229  682]\n",
      " [ 325  285  371]\n",
      " [ 272  351  950]\n",
      " [ 860  343  878]\n",
      " [ 584  170  820]\n",
      " [ 466  238  737]\n",
      " [ 857  254  149]\n",
      " [ 330  360  852]\n",
      " [ 780  264  537]\n",
      " [ 539  380  408]\n",
      " [ 548  135  785]\n",
      " [ 410   85  695]\n",
      " [ 726  262  153]\n",
      " [ 246  351  847]\n",
      " [ 422  213  592]\n",
      " [ 358  125  506]\n",
      " [ 845  429  770]\n",
      " [ 707  303  620]\n",
      " [ 770  327  597]\n",
      " [ 797  241  470]\n",
      " [ 521  495  505]\n",
      " [ 886  362  318]\n",
      " [ 532  478  717]\n",
      " [ 372  294  844]\n",
      " [ 726  441  443]\n",
      " [ 254  242  845]\n",
      " [ 439  342  989]\n",
      " [ 251  333  855]\n",
      " [ 677  404  594]\n",
      " [ 209  416  580]\n",
      " [ 592  178  274]\n",
      " [ 779  293  835]\n",
      " [ 862  364  388]\n",
      " [ 614  223  876]\n",
      " [ 393  458  715]\n",
      " [ 739  247  482]\n",
      " [ 618  303  231]\n",
      " [ 788  360  125]\n",
      " [ 427  217  723]\n",
      " [ 578  150  335]\n",
      " [ 737  342  882]\n",
      " [ 280  439  720]\n",
      " [ 645  389  752]\n",
      " [ 667  359  773]\n",
      " [ 326  252 1030]\n",
      " [ 804  407  247]\n",
      " [ 186  118  955]\n",
      " [ 494  343  351]\n",
      " [ 740  437 1028]\n",
      " [ 718  391  774]\n",
      " [ 872  296  180]\n",
      " [ 600  205  405]\n",
      " [ 545  364  996]\n",
      " [ 414  207 1000]\n",
      " [ 315  313  827]\n",
      " [ 265  265  925]\n",
      " [ 712  412  854]\n",
      " [ 640  509  574]\n",
      " [ 535  312  923]\n",
      " [ 369  447  513]\n",
      " [ 792  209  344]\n",
      " [ 200  329  734]\n",
      " [ 621  179  556]\n",
      " [ 219  314  532]\n",
      " [ 468  368  320]\n",
      " [ 888  412  453]\n",
      " [ 607  433  483]\n",
      " [ 347  187  855]\n",
      " [ 419  413  895]\n",
      " [ 693  294  675]\n",
      " [ 774  378  424]\n",
      " [ 599  471  555]\n",
      " [ 618  455  328]\n",
      " [ 871  450  562]\n",
      " [ 708  298  110]\n",
      " [ 671  413  941]\n",
      " [ 351  230 1035]\n",
      " [ 888  396  451]\n",
      " [ 584  300  845]\n",
      " [ 667  300  672]\n",
      " [ 674  312  986]\n",
      " [ 611  239  571]\n",
      " [ 909  312  228]\n",
      " [ 210  328  624]\n",
      " [ 459  295  275]\n",
      " [ 887  289  560]\n",
      " [ 339  474  721]\n",
      " [ 343  257  662]\n",
      " [ 350   59  857]\n",
      " [ 639  366 1045]\n",
      " [ 434  290  892]\n",
      " [ 485  227  824]\n",
      " [ 497  267  442]\n",
      " [ 458  425  364]\n",
      " [ 376  392  918]\n",
      " [ 879  236  470]\n",
      " [ 103  310  831]\n",
      " [ 681  268  985]\n",
      " [ 675  369  351]\n",
      " [ 426  261  778]\n",
      " [ 389  203  672]\n",
      " [ 717  396  511]\n",
      " [ 728  496  610]\n",
      " [ 761  268  567]\n",
      " [ 534  285  405]\n",
      " [ 791  378  879]\n",
      " [ 641   76  541]\n",
      " [ 944  329  315]\n",
      " [ 659  128  399]\n",
      " [ 177  340  773]\n",
      " [ 544  480  508]\n",
      " [ 534  316  316]\n",
      " [ 475  316  332]\n",
      " [ 883  419  743]\n",
      " [ 697  208  292]\n",
      " [ 700  378  628]\n",
      " [ 795  472  482]\n",
      " [ 132  261  877]\n",
      " [ 690  303  435]\n",
      " [ 452  176  604]\n",
      " [ 766  400  733]\n",
      " [ 275  247  376]\n",
      " [ 972  414  672]\n",
      " [ 882  251  570]\n",
      " [ 877  347  753]\n",
      " [ 288  144  889]\n",
      " [ 858  234  431]\n",
      " [ 717  320  830]\n",
      " [ 760  448  827]\n",
      " [ 550  416  893]\n",
      " [ 712  455  591]\n",
      " [ 908  364  533]\n",
      " [ 518  386  216]\n",
      " [ 885  375  737]\n",
      " [ 564   53  576]\n",
      " [ 541  447  466]\n",
      " [ 345  165  588]\n",
      " [ 852  249  372]\n",
      " [ 449  208  646]\n",
      " [ 216  171  961]\n",
      " [ 429  313  245]\n",
      " [ 674  440  562]\n",
      " [ 736  280  888]\n",
      " [ 406  482  504]\n",
      " [ 678  274  426]\n",
      " [ 438  347  368]\n",
      " [ 887  326  899]\n",
      " [ 470  419  333]\n",
      " [ 269  377  885]\n",
      " [ 534  235  830]\n",
      " [ 550  216  272]\n",
      " [ 266  223  861]\n",
      " [ 693  336  105]\n",
      " [ 219   84  992]\n",
      " [ 582  206  713]\n",
      " [ 341  294  877]\n",
      " [ 793  342  481]\n",
      " [ 780  223  163]\n",
      " [ 875  344  124]\n",
      " [ 876  309  795]\n",
      " [ 402  261  402]\n",
      " [ 711  357 1040]\n",
      " [ 838  369   50]\n",
      " [ 660  371  327]\n",
      " [ 924  285  283]\n",
      " [ 768  268  518]\n",
      " [ 716  289  451]\n",
      " [ 259  334  744]\n",
      " [ 249  298  487]\n",
      " [ 802  463  413]\n",
      " [ 405  305  875]\n",
      " [ 178  161  998]\n",
      " [ 620   57  700]\n",
      " [ 234  350  957]\n",
      " [ 803  257  483]\n",
      " [ 525   92  607]\n",
      " [ 786  486  653]\n",
      " [ 528  246  221]\n",
      " [ 411  327  282]\n",
      " [ 725  299  571]\n",
      " [ 893  265  210]\n",
      " [ 661  478  350]\n",
      " [ 271  374  739]\n",
      " [ 750  405  200]\n",
      " [ 976  374  708]\n",
      " [ 422  470  754]\n",
      " [ 790  331  565]\n",
      " [ 520  235  875]\n",
      " [ 543  264  147]\n",
      " [ 772  315  667]\n",
      " [ 570  200  864]\n",
      " [ 896  321  195]\n",
      " [ 823  384  738]\n",
      " [ 296  242  640]\n",
      " [ 940  280  524]\n",
      " [ 798  411  921]\n",
      " [ 195  327  531]\n",
      " [ 670  186  817]\n",
      " [ 795  266  513]\n",
      " [ 592  341  124]\n",
      " [ 629  181  376]\n",
      " [ 317  237  222]\n",
      " [ 642  369  789]\n",
      " [ 757  407  734]\n",
      " [ 625  415  279]\n",
      " [ 339  202  519]\n",
      " [ 791  401  978]\n",
      " [ 685  439  329]\n",
      " [ 498  362  217]\n",
      " [ 189  134  956]\n",
      " [ 600  279  431]\n",
      " [ 733  432  616]\n",
      " [ 278  261  659]\n",
      " [ 374  125  562]]\n",
      "Label 1: [[493 301 872]\n",
      " [497 288 563]\n",
      " [561 239 606]\n",
      " [400 445 576]\n",
      " [393 458 582]\n",
      " [583 394 728]\n",
      " [418 298 738]\n",
      " [387 414 478]\n",
      " [509 357 600]\n",
      " [399 296 694]\n",
      " [326 302 648]\n",
      " [505 451 592]\n",
      " [456 326 503]\n",
      " [491 279 485]\n",
      " [560 356 761]\n",
      " [326 292 657]\n",
      " [399 291 810]\n",
      " [393 308 840]\n",
      " [293 291 603]\n",
      " [476 284 684]\n",
      " [554 244 698]\n",
      " [442 427 539]\n",
      " [456 344 488]\n",
      " [486 432 661]\n",
      " [310 356 658]\n",
      " [291 391 715]\n",
      " [365 306 805]\n",
      " [328 314 497]\n",
      " [653 358 520]\n",
      " [463 396 775]\n",
      " [413 249 579]\n",
      " [455 320 690]\n",
      " [378 397 666]\n",
      " [346 330 633]\n",
      " [546 404 441]\n",
      " [556 314 677]\n",
      " [575 347 553]\n",
      " [476 286 632]\n",
      " [505 265 658]\n",
      " [485 244 682]\n",
      " [394 313 718]\n",
      " [433 287 563]\n",
      " [545 328 560]\n",
      " [344 363 581]\n",
      " [417 389 684]\n",
      " [347 317 508]\n",
      " [532 285 485]\n",
      " [376 357 761]\n",
      " [319 341 723]\n",
      " [471 351 526]\n",
      " [500 318 472]\n",
      " [315 344 653]\n",
      " [507 252 800]\n",
      " [539 383 660]\n",
      " [447 372 770]\n",
      " [371 349 539]\n",
      " [520 248 650]\n",
      " [512 369 684]\n",
      " [526 247 755]\n",
      " [268 421 630]\n",
      " [434 352 426]\n",
      " [302 282 590]\n",
      " [394 378 728]\n",
      " [586 389 516]\n",
      " [382 408 505]\n",
      " [254 357 675]\n",
      " [381 288 722]\n",
      " [461 374 677]\n",
      " [526 265 525]\n",
      " [525 354 556]\n",
      " [431 259 603]\n",
      " [512 298 485]\n",
      " [578 398 529]\n",
      " [364 329 815]\n",
      " [571 289 795]\n",
      " [484 410 754]\n",
      " [345 399 628]\n",
      " [510 362 523]\n",
      " [339 311 618]\n",
      " [400 369 490]\n",
      " [473 341 483]\n",
      " [455 301 857]\n",
      " [431 382 676]\n",
      " [398 403 706]\n",
      " [515 364 471]\n",
      " [406 428 693]\n",
      " [333 298 700]\n",
      " [540 383 732]\n",
      " [576 305 827]\n",
      " [536 364 443]\n",
      " [648 401 599]\n",
      " [528 396 759]\n",
      " [674 354 592]\n",
      " [465 354 566]\n",
      " [442 416 533]\n",
      " [435 442 547]\n",
      " [533 313 861]\n",
      " [456 444 737]\n",
      " [521 294 498]\n",
      " [300 330 568]\n",
      " [543 303 788]\n",
      " [337 376 741]\n",
      " [655 388 592]\n",
      " [584 322 668]\n",
      " [584 293 634]\n",
      " [382 337 453]\n",
      " [338 384 543]\n",
      " [554 378 437]\n",
      " [491 356 512]\n",
      " [367 266 688]\n",
      " [448 341 825]\n",
      " [585 363 783]\n",
      " [452 360 654]\n",
      " [313 316 682]\n",
      " [533 425 735]\n",
      " [466 442 579]\n",
      " [552 392 520]\n",
      " [653 365 690]\n",
      " [374 372 599]\n",
      " [421 348 450]\n",
      " [582 417 638]\n",
      " [437 277 514]\n",
      " [458 297 623]\n",
      " [389 378 668]\n",
      " [396 269 675]\n",
      " [453 378 647]\n",
      " [451 378 671]\n",
      " [611 388 592]\n",
      " [380 400 566]\n",
      " [306 345 639]\n",
      " [574 242 643]\n",
      " [303 360 592]\n",
      " [621 379 644]\n",
      " [528 274 793]\n",
      " [405 407 676]\n",
      " [390 312 526]\n",
      " [487 325 545]\n",
      " [520 300 737]\n",
      " [281 329 547]\n",
      " [267 343 543]\n",
      " [491 332 447]\n",
      " [347 436 645]\n",
      " [452 343 591]\n",
      " [438 351 509]\n",
      " [394 354 613]\n",
      " [600 373 517]\n",
      " [436 362 585]\n",
      " [349 308 611]\n",
      " [481 367 592]\n",
      " [395 435 614]\n",
      " [626 323 620]\n",
      " [442 433 617]\n",
      " [244 373 686]\n",
      " [340 294 605]\n",
      " [428 393 601]\n",
      " [415 317 479]\n",
      " [329 311 586]\n",
      " [503 455 585]\n",
      " [353 295 785]\n",
      " [338 380 660]\n",
      " [404 238 546]\n",
      " [558 297 578]\n",
      " [619 404 648]\n",
      " [650 357 617]\n",
      " [321 410 758]\n",
      " [523 385 740]\n",
      " [335 281 695]\n",
      " [397 315 691]\n",
      " [465 399 567]\n",
      " [328 345 507]\n",
      " [637 335 636]\n",
      " [607 366 718]\n",
      " [434 400 441]\n",
      " [300 386 602]\n",
      " [456 285 729]\n",
      " [401 458 634]\n",
      " [315 295 494]\n",
      " [432 361 775]\n",
      " [496 322 594]\n",
      " [506 311 738]\n",
      " [510 279 491]\n",
      " [614 398 502]\n",
      " [468 268 748]\n",
      " [551 431 542]\n",
      " [414 276 725]\n",
      " [461 350 437]\n",
      " [399 425 521]\n",
      " [564 355 453]\n",
      " [382 350 692]\n",
      " [421 290 762]\n",
      " [292 292 613]\n",
      " [397 361 525]\n",
      " [393 328 763]\n",
      " [466 342 514]\n",
      " [334 287 732]\n",
      " [321 342 605]\n",
      " [302 329 571]\n",
      " [309 338 613]\n",
      " [547 292 500]\n",
      " [541 449 634]\n",
      " [491 379 455]\n",
      " [617 299 638]\n",
      " [602 423 669]\n",
      " [419 385 627]\n",
      " [618 381 483]\n",
      " [499 276 531]\n",
      " [447 236 676]\n",
      " [474 347 584]\n",
      " [492 328 612]\n",
      " [423 320 516]\n",
      " [415 313 684]\n",
      " [441 342 511]\n",
      " [433 391 484]\n",
      " [451 374 467]\n",
      " [323 367 463]\n",
      " [294 310 537]\n",
      " [414 439 699]\n",
      " [442 377 493]\n",
      " [297 313 743]\n",
      " [441 358 435]\n",
      " [453 218 636]\n",
      " [583 288 661]\n",
      " [427 320 531]\n",
      " [434 411 700]\n",
      " [479 288 735]\n",
      " [519 220 592]\n",
      " [505 399 431]\n",
      " [471 275 795]\n",
      " [584 344 714]\n",
      " [338 360 645]\n",
      " [521 415 536]\n",
      " [365 245 557]\n",
      " [419 270 566]\n",
      " [352 315 679]\n",
      " [596 389 600]\n",
      " [455 356 513]\n",
      " [389 377 772]\n",
      " [426 394 553]\n",
      " [588 438 548]\n",
      " [509 345 536]\n",
      " [572 365 704]\n",
      " [515 356 703]\n",
      " [502 300 543]\n",
      " [375 378 522]\n",
      " [503 282 778]\n",
      " [521 312 457]\n",
      " [617 317 582]\n",
      " [279 336 552]\n",
      " [541 324 756]\n",
      " [556 327 536]\n",
      " [627 309 528]\n",
      " [535 374 666]\n",
      " [530 396 549]\n",
      " [672 355 659]\n",
      " [435 338 544]\n",
      " [423 417 669]]\n",
      "Label 2: [[ 632  429  226]\n",
      " [ 729  359  360]\n",
      " [ 478   90  557]\n",
      " [ 595  447  312]\n",
      " [ 497  261  884]\n",
      " [ 905  265  575]\n",
      " [ 691  373  152]\n",
      " [ 887  277  260]\n",
      " [ 664  115  674]\n",
      " [ 766  446  598]\n",
      " [ 854  356  758]\n",
      " [ 272  339  994]\n",
      " [ 691  466  736]\n",
      " [ 380   92  586]\n",
      " [ 668  141  762]\n",
      " [ 506  175  310]\n",
      " [ 197  308  929]\n",
      " [ 173  360  676]\n",
      " [ 425  413  387]\n",
      " [ 371  439  805]\n",
      " [ 541  280  887]\n",
      " [ 496  166  652]\n",
      " [ 439  399  958]\n",
      " [ 401  171  636]\n",
      " [ 468  179  983]\n",
      " [ 711  446  765]\n",
      " [ 176  219  978]\n",
      " [ 904  295  241]\n",
      " [ 499  415  916]\n",
      " [ 716  209  287]\n",
      " [ 774  472  747]\n",
      " [ 680  388  735]\n",
      " [ 700  410  151]\n",
      " [ 635  416  276]\n",
      " [ 512  368  901]\n",
      " [ 650  341  928]\n",
      " [ 799  270  718]\n",
      " [ 343  111  609]\n",
      " [ 894  255  468]\n",
      " [ 455  471  449]\n",
      " [ 168  314  855]\n",
      " [ 387  250  338]\n",
      " [ 360  286  319]\n",
      " [ 907  329  809]\n",
      " [ 664  323  980]\n",
      " [ 157  307  889]\n",
      " [ 344  319  298]\n",
      " [ 659  219  906]\n",
      " [ 658  446  836]\n",
      " [ 362  119  522]\n",
      " [ 654  431 1045]\n",
      " [ 823  211  240]\n",
      " [ 152  408  633]\n",
      " [ 804  450  597]\n",
      " [ 373  215  403]\n",
      " [ 937  325  727]\n",
      " [ 690  216  379]\n",
      " [ 603  188  806]\n",
      " [ 810  207  351]\n",
      " [ 447  113  486]\n",
      " [ 454   75  807]\n",
      " [ 889  315  779]\n",
      " [ 465  115  706]\n",
      " [ 636  426  508]\n",
      " [ 624  291  389]\n",
      " [ 412  247  261]\n",
      " [ 174  320  720]\n",
      " [ 503  151  564]\n",
      " [ 572  320  880]\n",
      " [ 496  167  654]\n",
      " [ 908  324  338]\n",
      " [ 909  384  515]\n",
      " [ 233  254 1033]\n",
      " [ 644  291  123]\n",
      " [ 397   68  608]\n",
      " [ 784  280  742]\n",
      " [ 925  328  763]\n",
      " [ 729  254  313]\n",
      " [ 334  223  481]\n",
      " [ 429  107  848]\n",
      " [ 361   92  570]\n",
      " [ 582  244  419]\n",
      " [ 578  441  285]\n",
      " [ 909  321  105]\n",
      " [ 897  312  471]\n",
      " [ 440  332 1035]\n",
      " [ 348  360  916]\n",
      " [ 793  288  895]\n",
      " [ 849  300  769]\n",
      " [ 721  232  521]\n",
      " [ 660  306  859]\n",
      " [ 358  221  488]\n",
      " [ 629  467  674]\n",
      " [ 446  494  589]\n",
      " [ 605  218  369]\n",
      " [ 861  382  475]\n",
      " [ 483  240  977]\n",
      " [ 553  139  581]\n",
      " [ 780  452  604]\n",
      " [ 157  290  877]\n",
      " [ 569  156  802]\n",
      " [ 115  316  815]\n",
      " [ 572   47  601]\n",
      " [ 292  269  269]\n",
      " [ 345  265  277]\n",
      " [ 716  144  623]\n",
      " [ 583  167  311]\n",
      " [ 303  169  973]\n",
      " [ 620  285  128]\n",
      " [ 789  439  614]\n",
      " [ 338  225  506]\n",
      " [ 211  118 1019]\n",
      " [ 375   84  554]\n",
      " [ 345  223  864]\n",
      " [ 500   38  763]\n",
      " [ 917  305  418]\n",
      " [ 783  241  694]\n",
      " [ 588  434  816]\n",
      " [ 526  120  461]\n",
      " [ 792  191  586]\n",
      " [ 320  426  500]\n",
      " [ 620  458  785]\n",
      " [ 304  263  657]\n",
      " [ 672  468  724]\n",
      " [ 413  274  218]\n",
      " [ 486  118  421]\n",
      " [ 632  377  190]\n",
      " [ 265  268  770]\n",
      " [ 822  206  533]\n",
      " [ 581  188  361]\n",
      " [ 297   61  825]\n",
      " [ 558  454  357]\n",
      " [ 182  404  572]\n",
      " [ 541   57  689]\n",
      " [ 506  137  674]\n",
      " [ 526   76  775]\n",
      " [ 953  322  492]\n",
      " [ 569  165  292]\n",
      " [ 692  412  476]\n",
      " [ 709  377 1050]\n",
      " [ 800  361   83]\n",
      " [ 775  172  562]\n",
      " [ 538   36  697]\n",
      " [ 386  451  459]\n",
      " [ 656  359   93]\n",
      " [ 365  240  975]\n",
      " [ 448  167  634]\n",
      " [ 378  181  626]\n",
      " [ 465  394  399]\n",
      " [ 407  271  321]\n",
      " [ 798  352  268]\n",
      " [ 189  306 1031]\n",
      " [ 617  433  306]\n",
      " [ 482   65  695]\n",
      " [ 721  299  817]\n",
      " [ 815  406  670]\n",
      " [ 712  307  298]\n",
      " [ 746  274  821]\n",
      " [ 448  129  907]\n",
      " [ 626  369  911]\n",
      " [ 612  148  716]\n",
      " [ 499  411  886]\n",
      " [ 392  218  380]\n",
      " [ 461  303 1032]\n",
      " [ 737  157  418]\n",
      " [ 770  371 1008]\n",
      " [ 118  359  750]\n",
      " [ 691  288  729]\n",
      " [ 522  177  332]\n",
      " [ 487  223  979]\n",
      " [ 269  124  869]\n",
      " [ 565  110  691]\n",
      " [ 887  389  620]\n",
      " [ 553  196  241]\n",
      " [ 773  251  863]\n",
      " [ 462  254  905]\n",
      " [ 731  156  604]\n",
      " [ 716  357  401]\n",
      " [ 258  205  944]\n",
      " [ 637  354  861]\n",
      " [ 434   40  678]\n",
      " [ 373  193  404]\n",
      " [ 152  386  799]\n",
      " [ 737  251  807]\n",
      " [ 398  166  405]\n",
      " [ 253  246  447]\n",
      " [ 745  381  813]\n",
      " [ 412  315 1003]\n",
      " [ 546  339 1020]\n",
      " [ 795  368  228]\n",
      " [ 696  414  327]\n",
      " [ 667  256  819]\n",
      " [ 317  346  928]\n",
      " [ 441  166  943]\n",
      " [ 620  214  394]\n",
      " [ 557  256  974]\n",
      " [ 204  408  758]\n",
      " [ 312  187  479]\n",
      " [ 774  362   71]\n",
      " [ 707  350  786]\n",
      " [ 734  358   96]\n",
      " [ 761  382  972]\n",
      " [ 880  359  571]\n",
      " [ 372  213  960]\n",
      " [ 976  345  735]\n",
      " [ 356  221  532]\n",
      " [ 439  149  579]\n",
      " [ 238  284  506]\n",
      " [ 806  479  573]\n",
      " [ 304  176  474]\n",
      " [ 585  289  426]\n",
      " [ 392  464  515]\n",
      " [ 660  257  534]\n",
      " [ 694  307  912]\n",
      " [ 615  373  267]\n",
      " [ 502  298  151]\n",
      " [ 750  378  306]\n",
      " [ 652  395  948]\n",
      " [ 247  250  511]\n",
      " [ 570  184  292]\n",
      " [ 318  214  443]\n",
      " [ 354  207  375]\n",
      " [ 337  267  897]\n",
      " [ 551  484  493]\n",
      " [ 498  196  973]\n",
      " [ 620  301  280]\n",
      " [ 339  218  505]\n",
      " [ 404  376  371]\n",
      " [ 285  285  843]\n",
      " [ 745  415  364]\n",
      " [ 743  264  734]\n",
      " [ 811  440  833]\n",
      " [ 443  472  722]\n",
      " [ 683  450  850]\n",
      " [ 922  295  613]\n",
      " [ 616  399  175]\n",
      " [ 515  224  964]\n",
      " [ 658  138  658]\n",
      " [ 409  425  439]\n",
      " [ 660  359  769]\n",
      " [ 893  439  645]\n",
      " [ 882  421  705]\n",
      " [ 576  156  675]\n",
      " [ 465  200  817]\n",
      " [ 309  221  868]\n",
      " [ 445   86  708]\n",
      " [ 407   55  626]\n",
      " [ 640  261  491]\n",
      " [ 741  297  961]\n",
      " [ 758  465  328]\n",
      " [ 797  341  972]\n",
      " [ 819  234  713]\n",
      " [ 513  304  324]\n",
      " [ 857  373  346]\n",
      " [ 357  234  655]\n",
      " [ 276  383  937]]\n",
      "Label 3: [[ 719  268  193]\n",
      " [ 414  383  924]\n",
      " [ 309  187  414]\n",
      " [ 690  330  396]\n",
      " [ 788  327  441]\n",
      " [ 630  288  509]\n",
      " [ 554  418 1049]\n",
      " [ 491  160  347]\n",
      " [ 738  418  906]\n",
      " [ 798  300  187]\n",
      " [ 864  297  469]\n",
      " [ 814  328  786]\n",
      " [ 807  278  434]\n",
      " [ 564   71  741]\n",
      " [ 448  219  332]\n",
      " [ 819  311  874]\n",
      " [ 633  290  797]\n",
      " [ 498  286  953]\n",
      " [ 244  213  972]\n",
      " [ 566  166  630]\n",
      " [ 348  127  944]\n",
      " [ 454   74  674]\n",
      " [ 625   80  701]\n",
      " [ 869  401  637]\n",
      " [ 824  316  925]\n",
      " [ 565   78  745]\n",
      " [ 445  209  339]\n",
      " [ 409  213  348]\n",
      " [ 761  372  586]\n",
      " [ 803  434  452]\n",
      " [ 717  466  536]\n",
      " [ 456  207  549]\n",
      " [ 588  247  223]\n",
      " [ 868  270  594]\n",
      " [ 557  453  666]\n",
      " [ 721  199  578]\n",
      " [ 616  107  561]\n",
      " [ 465  267  344]\n",
      " [ 672  330  869]\n",
      " [ 735  273  303]\n",
      " [ 492   76  747]\n",
      " [ 597  175  500]\n",
      " [ 363  161  953]\n",
      " [ 395  159  512]\n",
      " [ 464  352  354]\n",
      " [ 760  372  691]\n",
      " [ 748  344  650]\n",
      " [ 791  326  487]\n",
      " [ 751  349  883]\n",
      " [ 768  371  595]\n",
      " [ 641  333  244]\n",
      " [ 425   48  740]\n",
      " [ 590  436  724]\n",
      " [ 866  343  794]\n",
      " [ 769  265  273]\n",
      " [ 689  332  360]\n",
      " [ 504  226  839]\n",
      " [ 431  371  927]\n",
      " [ 628  451  629]\n",
      " [ 246  254  961]\n",
      " [ 837  268  827]\n",
      " [ 668  403  471]\n",
      " [ 502  367  364]\n",
      " [ 483   94  776]\n",
      " [ 391  380 1036]\n",
      " [ 557  235  879]\n",
      " [ 653  191  549]\n",
      " [ 644  165  540]\n",
      " [ 612  318  941]\n",
      " [ 282  461  600]\n",
      " [ 333  136  485]\n",
      " [ 681  175  516]\n",
      " [ 297  181 1032]\n",
      " [ 639  181  540]\n",
      " [ 619  259  826]\n",
      " [ 588  138  532]\n",
      " [ 193  290  872]\n",
      " [ 737  196  623]\n",
      " [ 299  371  789]\n",
      " [ 639  238  770]\n",
      " [ 491   89  564]\n",
      " [ 518   67  639]\n",
      " [ 454  375 1032]\n",
      " [ 714  172  560]\n",
      " [ 782  264  213]\n",
      " [ 763  369  697]\n",
      " [ 710  204  575]\n",
      " [ 498  200  314]\n",
      " [ 520  207  429]\n",
      " [ 637  252  810]\n",
      " [ 546  312  988]\n",
      " [ 436  257  343]\n",
      " [ 249  200 1044]\n",
      " [ 817  387  718]\n",
      " [ 449  222  884]\n",
      " [ 795  314  394]\n",
      " [ 497  252  467]\n",
      " [ 665  165  489]\n",
      " [ 551  319  202]\n",
      " [ 358  122  591]\n",
      " [ 755  463  677]\n",
      " [ 555  282  468]\n",
      " [ 500  334  361]\n",
      " [ 495  132  453]\n",
      " [ 659  169  530]\n",
      " [ 437  234  304]\n",
      " [ 566  152  465]\n",
      " [ 845  376  653]\n",
      " [ 764  428  794]\n",
      " [ 398   70  769]\n",
      " [ 790  356  672]\n",
      " [ 257  185 1018]\n",
      " [ 712  354  650]\n",
      " [ 607  110  522]\n",
      " [ 553  203  382]\n",
      " [ 599  259  381]\n",
      " [ 526  409 1025]\n",
      " [ 560  177  660]\n",
      " [ 530   81  762]\n",
      " [ 310  290  979]\n",
      " [ 682  276  748]\n",
      " [ 685  335  274]\n",
      " [ 496  348 1003]\n",
      " [ 278  385  883]\n",
      " [ 733  310  839]\n",
      " [ 508  351  999]\n",
      " [ 428  198  280]\n",
      " [ 361  256  796]\n",
      " [ 793  250  362]\n",
      " [ 706  360  494]\n",
      " [ 560  298  162]\n",
      " [ 533  299  227]\n",
      " [ 353  370  993]\n",
      " [ 796  457  725]\n",
      " [ 540  198  400]\n",
      " [ 639  269  646]\n",
      " [ 641  406  811]\n",
      " [ 356  375  997]\n",
      " [ 704  266  359]\n",
      " [ 436  276  382]\n",
      " [ 350  223 1036]\n",
      " [ 804  326  326]\n",
      " [ 706  370  263]\n",
      " [ 810  420  591]\n",
      " [ 594  324  947]\n",
      " [ 774  380  347]\n",
      " [ 474   89  665]\n",
      " [ 668  157  645]\n",
      " [ 549  327  922]\n",
      " [ 610  304  154]\n",
      " [ 591  473  622]\n",
      " [ 597  351  427]\n",
      " [ 497   73  768]\n",
      " [ 476  291  950]\n",
      " [ 438  308  267]\n",
      " [ 620  133  581]\n",
      " [ 818  430  612]\n",
      " [ 453  277  323]\n",
      " [ 794  217  749]\n",
      " [ 655  379  284]\n",
      " [ 484  225  373]\n",
      " [ 496   90  585]\n",
      " [ 669  412  475]\n",
      " [ 660  247  693]\n",
      " [ 595  243  937]\n",
      " [ 585  395 1029]\n",
      " [ 534  238  337]\n",
      " [ 657  245  728]\n",
      " [ 474  176  451]\n",
      " [ 865  349  671]\n",
      " [ 825  284  697]\n",
      " [ 713  215  563]\n",
      " [ 303  264  911]\n",
      " [ 264  305  926]\n",
      " [ 903  386  634]\n",
      " [ 844  290  250]\n",
      " [ 794  335  836]\n",
      " [ 803  303  329]\n",
      " [ 562  285  219]\n",
      " [ 199  327  898]\n",
      " [ 626  198  729]\n",
      " [ 652  132  434]\n",
      " [ 223  397  759]\n",
      " [ 772  235  309]\n",
      " [ 485  143  516]\n",
      " [ 495   78  582]\n",
      " [ 537  334  984]\n",
      " [ 828  275  737]\n",
      " [ 376  269 1019]\n",
      " [ 177  194  952]\n",
      " [ 491  283  434]\n",
      " [ 710  374  566]\n",
      " [ 522  328  330]\n",
      " [ 423  257  332]\n",
      " [ 550  153  592]\n",
      " [ 681  300  262]\n",
      " [ 750  342  737]\n",
      " [ 719  219  585]\n",
      " [ 327  206  401]\n",
      " [ 647  229  740]\n",
      " [ 733  382  242]\n",
      " [ 756  363  238]\n",
      " [ 497  318  257]\n",
      " [ 278  363  815]\n",
      " [ 758  458  436]\n",
      " [ 812  421  787]\n",
      " [ 303  363  798]\n",
      " [ 704  445  588]\n",
      " [ 347  160  936]\n",
      " [ 647  265  672]\n",
      " [ 724  209  622]\n",
      " [ 364  319  898]\n",
      " [ 690  278  203]\n",
      " [ 465  263  428]\n",
      " [ 538  296 1012]\n",
      " [ 698  352  249]\n",
      " [ 522  358  276]\n",
      " [ 834  300  756]\n",
      " [ 345  155  492]\n",
      " [ 811  408  509]\n",
      " [ 758  362  685]\n",
      " [ 698  302  846]\n",
      " [ 682  366  240]\n",
      " [ 562  180  472]\n",
      " [ 321  389  822]\n",
      " [ 762  451  731]\n",
      " [ 618  131  512]\n",
      " [ 710  251  211]\n",
      " [ 754  365  577]\n",
      " [ 784  257  228]\n",
      " [ 461  254 1002]\n",
      " [ 757  456  502]\n",
      " [ 544  219  430]\n",
      " [ 426  172  498]\n",
      " [ 504  319  373]\n",
      " [ 487  413  374]\n",
      " [ 270  113  987]\n",
      " [ 763  338  707]\n",
      " [ 545  347  404]\n",
      " [ 692  385  272]\n",
      " [ 599  409  438]\n",
      " [ 436  132  467]\n",
      " [ 483  402  373]\n",
      " [ 631  272  372]\n",
      " [ 422  145  342]\n",
      " [ 517  174  477]\n",
      " [ 602  344  438]\n",
      " [ 370  186  456]\n",
      " [ 559  318  257]\n",
      " [ 552  295  183]\n",
      " [ 605  400  379]\n",
      " [ 659  376  258]\n",
      " [ 747  368  243]\n",
      " [ 717  451  480]\n",
      " [ 419  185  290]\n",
      " [ 393  239 1010]]\n"
     ]
    }
   ],
   "source": [
    "for label, coords in selected_pixel_coords.items():\n",
    "    print(f\"Label {label}: {coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_as_pickle(selected_pixel_coords, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(selected_pixel_coords, f)\n",
    "\n",
    "# Usage\n",
    "save_as_pickle(selected_pixel_coords, 'selected_pixel_coords.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image, coords, patch_size=(64,64)):\n",
    "    half_size_y = patch_size[0] // 2\n",
    "    half_size_x = patch_size[1] // 2\n",
    "    patches = []\n",
    "\n",
    "    # Get the shape of the image\n",
    "    _, y_max, x_max = image.shape\n",
    "\n",
    "    for coord in coords:\n",
    "        z, y, x = coord\n",
    "\n",
    "        # Calculate the boundaries of the patch\n",
    "        x_start = max(0, x - half_size_x)\n",
    "        x_end = min(x_max, x + half_size_x)\n",
    "        y_start = max(0, y - half_size_y)\n",
    "        y_end = min(y_max, y + half_size_y)\n",
    "\n",
    "        \n",
    "        # Extract the patch from the image\n",
    "        patch = image[z, y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Check if the patch is the required size, otherwise pad with zeros\n",
    "        if patch.shape != patch_size:\n",
    "            print(\"something is wrong\")\n",
    "\n",
    "        \n",
    "        # Store the patch\n",
    "        patches.append(patch)\n",
    "\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches for label 0: torch.Size([256, 1, 64, 64])\n",
      "Patches for label 1: torch.Size([256, 1, 64, 64])\n",
      "Patches for label 2: torch.Size([256, 1, 64, 64])\n",
      "Patches for label 3: torch.Size([256, 1, 64, 64])\n",
      "torch.Size([8, 128, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "all_patches_tensors = []\n",
    "\n",
    "for label, coords in selected_pixel_coords.items():\n",
    "    patches = extract_patches(test_images, coords, patch_size=patch_size)\n",
    "    patches_tensor = torch.tensor(patches, dtype=torch.float32).unsqueeze(1)\n",
    "    print(f\"Patches for label {label}: {patches_tensor.shape}\")  # The shape should be (256, 64, 64)\n",
    "    all_patches_tensors.append(patches_tensor)\n",
    "\n",
    "combined_tensor = torch.stack(all_patches_tensors, dim=0).reshape(8, 128, 1, 64, 64)\n",
    "print(combined_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_5x5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 1x1_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/group/jug/Sheida/HVAE/2D/\"\n",
    "model_versions = ['5x5_5x5', '5x5_3x3', '3x3_3x3', '5x5_1x1', '3x3_1x1', '1x1_1x1']\n",
    "batch_size = 128\n",
    "for model_v in model_versions:\n",
    "    model = torch.load(model_dir+'supervised_'+str(model_v)+\"/model/2D_HVAE_best_vae.net\")\n",
    "    data_mean = model.data_mean\n",
    "    data_std = model.data_std\n",
    "    model.mode_pred = True\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    print(f\"Processing 1024 pixels with model version supervised {model_v}\")\n",
    "    index = 0 \n",
    "    all_mus = np.zeros((1024, 43008), dtype=np.float16)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(combined_tensor):\n",
    "            batch = batch.to(device)\n",
    "            batch = (batch - data_mean) / data_std\n",
    "            output = model(batch)\n",
    "            mu_test = torch.cat([output[\"mu\"][i].reshape(batch_size, -1) for i in range(hierarchy_level)], dim=1)\n",
    "            mu_test = np.array(mu_test.cpu().numpy())\n",
    "            all_mus[index:index+batch_size] = mu_test\n",
    "            index += batch_size\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_mus)\n",
    "    cluster_labels = cluster_labels.reshape(4, 256)\n",
    "    tiff.imwrite(f\"{model_dir}supervised_{model_v}/1000pixels.tif\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 245, 2: 9, 3: 2}\n",
      "{0: 242, 1: 14}\n",
      "{1: 91, 2: 163, 3: 2}\n",
      "{1: 137, 2: 2, 3: 117}\n",
      "{0: 1, 1: 242, 2: 11, 3: 2}\n",
      "{0: 248, 1: 8}\n",
      "{1: 53, 2: 201, 3: 2}\n",
      "{1: 116, 2: 4, 3: 136}\n",
      "{0: 1, 1: 236, 2: 12, 3: 7}\n",
      "{0: 241, 1: 15}\n",
      "{1: 56, 2: 198, 3: 2}\n",
      "{1: 110, 2: 2, 3: 144}\n",
      "{0: 4, 1: 16, 2: 213, 3: 23}\n",
      "{0: 253, 2: 3}\n",
      "{1: 197, 2: 57, 3: 2}\n",
      "{1: 2, 2: 90, 3: 164}\n",
      "{0: 5, 1: 15, 2: 220, 3: 16}\n",
      "{0: 251, 2: 4, 3: 1}\n",
      "{0: 1, 1: 206, 2: 39, 3: 10}\n",
      "{1: 3, 2: 110, 3: 143}\n",
      "{0: 4, 1: 18, 2: 220, 3: 14}\n",
      "{0: 245, 2: 11}\n",
      "{0: 1, 1: 5, 2: 53, 3: 197}\n",
      "{1: 197, 2: 55, 3: 4}\n"
     ]
    }
   ],
   "source": [
    "seg = []\n",
    "for i in range(len(model_versions)):\n",
    "    seg.append(tiff.imread(f\"{model_dir}supervised_{model_versions[i]}/1000pixels.tif\"))\n",
    "    for j in range(4):\n",
    "        print(count_label_pixels(seg[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def compute_dice_coefficient(ground_truth, predicted):\n",
    "    \"\"\"\n",
    "    Compute Dice coefficient between ground truth and predicted segmentation after resolving label permutations.\n",
    "    \n",
    "    Args:\n",
    "    - ground_truth (numpy array): Ground truth labels (values from 0 to 3).\n",
    "    - predicted (numpy array): Predicted labels (after clustering, might be permuted).\n",
    "    \n",
    "    Returns:\n",
    "    - dice_coefficients (list): Dice coefficients for each class (label).\n",
    "    \"\"\"\n",
    "    # Ensure both arrays are 1D\n",
    "    ground_truth = ground_truth.flatten()\n",
    "    predicted = predicted.flatten()\n",
    "    \n",
    "    # Create a confusion matrix\n",
    "    # Rows: Ground truth labels (0 to 3)\n",
    "    # Columns: Predicted cluster labels (0 to 3, possibly permuted)\n",
    "    conf_matrix = confusion_matrix(ground_truth, predicted, labels=[0, 1, 2, 3])\n",
    "    \n",
    "    # Use the Hungarian algorithm to find the optimal label assignment (best permutation)\n",
    "    row_ind, col_ind = linear_sum_assignment(-conf_matrix)  # Negative because it's maximization problem\n",
    "    \n",
    "    # Re-map predicted labels to match ground truth\n",
    "    remapped_predicted = np.zeros_like(predicted)\n",
    "    for gt_label, pred_label in zip(row_ind, col_ind):\n",
    "        remapped_predicted[predicted == pred_label] = gt_label\n",
    "    \n",
    "    # Compute Dice coefficient for each class\n",
    "    dice_coefficients = []\n",
    "    for label in np.unique(ground_truth):\n",
    "        gt_binary = (ground_truth == label)\n",
    "        pred_binary = (remapped_predicted == label)\n",
    "        \n",
    "        intersection = np.sum(gt_binary & pred_binary)\n",
    "        dice = (2. * intersection) / (np.sum(gt_binary) + np.sum(pred_binary))\n",
    "        dice_coefficients.append(dice)\n",
    "    \n",
    "    return dice_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.zeros((4, 256), dtype=np.uint8)\n",
    "gt[0] = 0\n",
    "gt[1] = 1\n",
    "gt[2] = 2\n",
    "gt[3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version supervised 5x5_5x5:\n",
      "[0.6594885598923284, 0.9718875502008032, 0.7581395348837209, 0.6206896551724138]\n",
      "Model version supervised 5x5_3x3:\n",
      "[0.717037037037037, 0.9821782178217822, 0.8516949152542372, 0.6868686868686869]\n",
      "Model version supervised 3x3_3x3:\n",
      "[0.7013372956909361, 0.9678714859437751, 0.8461538461538461, 0.7041564792176039]\n",
      "Model version supervised 5x5_1x1:\n",
      "[0.6882067851373183, 0.98635477582846, 0.8365180467091295, 0.7370786516853932]\n",
      "Model version supervised 3x3_1x1:\n",
      "[0.699523052464229, 0.9785575048732943, 0.8583333333333333, 0.6713615023474179]\n",
      "Model version supervised 1x1_1x1:\n",
      "[0.7394957983193278, 0.9683794466403162, 0.8365180467091295, 0.8277310924369747]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(seg)):\n",
    "    dice_scores = compute_dice_coefficient(gt, seg[i])\n",
    "    print(f\"Model version supervised {model_versions[i]}:\")\n",
    "    print(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_5x5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 1x1_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/group/jug/Sheida/HVAE/2D/\"\n",
    "model_versions = ['5x5_5x5', '5x5_3x3', '3x3_3x3', '5x5_1x1', '3x3_1x1', '1x1_1x1']\n",
    "batch_size = 128\n",
    "for model_v in model_versions:\n",
    "    model = torch.load(model_dir+'10p_semi_'+str(model_v)+\"/model/2D_HVAE_best_vae.net\")\n",
    "    data_mean = model.data_mean\n",
    "    data_std = model.data_std\n",
    "    model.mode_pred = True\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    print(f\"Processing 1024 pixels with model version supervised {model_v}\")\n",
    "    index = 0 \n",
    "    all_mus = np.zeros((1024, 43008), dtype=np.float16)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(combined_tensor):\n",
    "            batch = batch.to(device)\n",
    "            batch = (batch - data_mean) / data_std\n",
    "            output = model(batch)\n",
    "            mu_test = torch.cat([output[\"mu\"][i].reshape(batch_size, -1) for i in range(hierarchy_level)], dim=1)\n",
    "            mu_test = np.array(mu_test.cpu().numpy())\n",
    "            all_mus[index:index+batch_size] = mu_test\n",
    "            index += batch_size\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_mus)\n",
    "    cluster_labels = cluster_labels.reshape(4, 256)\n",
    "    tiff.imwrite(f\"{model_dir}10p_semi_{model_v}/1000pixels.tif\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 253, 2: 2, 3: 1}\n",
      "{0: 229, 1: 27}\n",
      "{1: 242, 3: 14}\n",
      "{1: 231, 2: 25}\n",
      "{0: 1, 1: 238, 2: 12, 3: 5}\n",
      "{0: 233, 1: 23}\n",
      "{1: 120, 2: 136}\n",
      "{1: 180, 2: 2, 3: 74}\n",
      "{1: 245, 2: 5, 3: 6}\n",
      "{0: 213, 1: 43}\n",
      "{1: 121, 2: 133, 3: 2}\n",
      "{1: 118, 2: 7, 3: 131}\n",
      "{0: 3, 1: 231, 2: 18, 3: 4}\n",
      "{0: 248, 1: 8}\n",
      "{1: 89, 2: 165, 3: 2}\n",
      "{0: 1, 1: 119, 2: 5, 3: 131}\n",
      "{1: 232, 2: 11, 3: 13}\n",
      "{0: 238, 1: 16, 2: 1, 3: 1}\n",
      "{1: 98, 2: 153, 3: 5}\n",
      "{1: 126, 2: 5, 3: 125}\n",
      "{0: 2, 1: 223, 2: 17, 3: 14}\n",
      "{0: 241, 1: 13, 2: 2}\n",
      "{1: 80, 2: 6, 3: 170}\n",
      "{1: 46, 2: 205, 3: 5}\n"
     ]
    }
   ],
   "source": [
    "semi_10_seg = []\n",
    "for i in range(len(model_versions)):\n",
    "    semi_10_seg.append(tiff.imread(f\"{model_dir}10p_semi_{model_versions[i]}/1000pixels.tif\"))\n",
    "    for j in range(4):\n",
    "        print(count_label_pixels(semi_10_seg[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version SS 10% 5x5_5x5:\n",
      "[0.5014866204162537, 0.9443298969072165, 0.1033210332103321, 0.17667844522968199]\n",
      "Model version SS 10% 5x5_3x3:\n",
      "[0.5826193390452876, 0.9510204081632653, 0.6699507389162561, 0.4417910447761194]\n",
      "Model version SS 10% 3x3_3x3:\n",
      "[0.6257982120051085, 0.908315565031983, 0.6633416458852868, 0.6632911392405063]\n",
      "Model version SS 10% 5x5_1x1:\n",
      "[0.6571834992887624, 0.9763779527559056, 0.7432432432432432, 0.6666666666666666]\n",
      "Model version SS 10% 3x3_1x1:\n",
      "[0.6373626373626373, 0.9635627530364372, 0.7183098591549296, 0.625]\n",
      "Model version SS 10% 1x1_1x1:\n",
      "[0.7216828478964401, 0.9659318637274549, 0.7640449438202247, 0.8436213991769548]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(semi_10_seg)):\n",
    "    dice_scores = compute_dice_coefficient(gt, semi_10_seg[i])\n",
    "    print(f\"Model version SS 10% {model_versions[i]}:\")\n",
    "    print(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_5x5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_3x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 5x5_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 3x3_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1024 pixels with model version supervised 1x1_1x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.38it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/group/jug/Sheida/HVAE/2D/\"\n",
    "model_versions = ['5x5_5x5', '5x5_3x3', '3x3_3x3', '5x5_1x1', '3x3_1x1', '1x1_1x1']\n",
    "batch_size = 128\n",
    "for model_v in model_versions:\n",
    "    model = torch.load(model_dir+'1p_semi_'+str(model_v)+\"/model/2D_HVAE_best_vae.net\")\n",
    "    data_mean = model.data_mean\n",
    "    data_std = model.data_std\n",
    "    model.mode_pred = True\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    print(f\"Processing 1024 pixels with model version supervised {model_v}\")\n",
    "    index = 0 \n",
    "    all_mus = np.zeros((1024, 43008), dtype=np.float16)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(combined_tensor):\n",
    "            batch = batch.to(device)\n",
    "            batch = (batch - data_mean) / data_std\n",
    "            output = model(batch)\n",
    "            mu_test = torch.cat([output[\"mu\"][i].reshape(batch_size, -1) for i in range(hierarchy_level)], dim=1)\n",
    "            mu_test = np.array(mu_test.cpu().numpy())\n",
    "            all_mus[index:index+batch_size] = mu_test\n",
    "            index += batch_size\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_mus)\n",
    "    cluster_labels = cluster_labels.reshape(4, 256)\n",
    "    tiff.imwrite(f\"{model_dir}1p_semi_{model_v}/1000pixels.tif\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 246, 2: 7, 3: 1}\n",
      "{0: 183, 1: 42, 2: 31}\n",
      "{1: 247, 3: 9}\n",
      "{0: 6, 1: 227, 2: 20, 3: 3}\n",
      "{1: 1, 2: 248, 3: 7}\n",
      "{0: 177, 1: 56, 2: 23}\n",
      "{2: 232, 3: 24}\n",
      "{2: 215, 3: 41}\n",
      "{0: 3, 1: 225, 2: 11, 3: 17}\n",
      "{0: 244, 1: 12}\n",
      "{1: 203, 2: 3, 3: 50}\n",
      "{0: 2, 1: 178, 2: 63, 3: 13}\n",
      "{1: 195, 2: 20, 3: 41}\n",
      "{0: 202, 1: 30, 2: 16, 3: 8}\n",
      "{1: 182, 2: 32, 3: 42}\n",
      "{1: 192, 2: 20, 3: 44}\n",
      "{0: 1, 1: 183, 2: 57, 3: 15}\n",
      "{0: 207, 1: 16, 2: 1, 3: 32}\n",
      "{1: 161, 2: 89, 3: 6}\n",
      "{0: 1, 1: 155, 2: 48, 3: 52}\n",
      "{1: 52, 2: 198, 3: 6}\n",
      "{0: 205, 2: 46, 3: 5}\n",
      "{1: 94, 2: 160, 3: 2}\n",
      "{1: 81, 2: 96, 3: 79}\n"
     ]
    }
   ],
   "source": [
    "semi_1_seg = []\n",
    "for i in range(len(model_versions)):\n",
    "    semi_1_seg.append(tiff.imread(f\"{model_dir}1p_semi_{model_versions[i]}/1000pixels.tif\"))\n",
    "    for j in range(4):\n",
    "        print(count_label_pixels(semi_1_seg[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version SS 1% 5x5_5x5:\n",
      "[0.48330058939096265, 0.8187919463087249, 0.06691449814126393, 0.12738853503184713]\n",
      "Model version SS 1% 5x5_3x3:\n",
      "[0.5092402464065708, 0.8175519630484989, 0.0, 0.25]\n",
      "Model version SS 1% 3x3_3x3:\n",
      "[0.5148741418764302, 0.9663366336633663, 0.2976190476190476, 0.3783783783783784]\n",
      "Model version SS 1% 5x5_1x1:\n",
      "[0.45614035087719296, 0.8820960698689956, 0.18604651162790697, 0.22506393861892582]\n",
      "Model version SS 1% 3x3_1x1:\n",
      "[0.47470817120622566, 0.8903225806451613, 0.3946784922394678, 0.2880886426592798]\n",
      "Model version SS 1% 1x1_1x1:\n",
      "[0.5238095238095238, 0.8893709327548807, 0.38923395445134573, 0.4540229885057471]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(semi_1_seg)):\n",
    "    dice_scores = compute_dice_coefficient(gt, semi_1_seg[i])\n",
    "    print(f\"Model version SS 1% {model_versions[i]}:\")\n",
    "    print(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
