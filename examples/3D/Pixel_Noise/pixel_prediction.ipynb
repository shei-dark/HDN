{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('/home/sheida.rahnamai/GIT/HDN/')\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "# from lib.dataloader import CustomTestDataset\n",
    "from boilerplate.dataloader import Custom3DTestDataset\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from boilerplate import boilerplate\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch.nn.functional import unfold\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "dist_metric = ['cosine']\n",
    "\n",
    "num_clusters = 4\n",
    "patch_size = (8,64,64)\n",
    "centre_size = 5\n",
    "n_channel = 32\n",
    "hierarchy_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image loaded from path:\n",
      "/group/jug/Sheida/pancreatic beta cells/download/high_c4/high_c4_source.tif\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/group/jug/Sheida/pancreatic beta cells/download/\"\n",
    "\n",
    "One_test_image = ['high_c4']\n",
    "\n",
    "# Load test image\n",
    "test_img_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_source.tif\")\n",
    "test_images = tiff.imread(test_img_path)\n",
    "\n",
    "# Print loaded test images paths\n",
    "print(\"Test image loaded from path:\")\n",
    "print(test_img_path)\n",
    "\n",
    "# Load test ground truth images\n",
    "test_gt_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_gt.tif\")\n",
    "test_ground_truth_image = tiff.imread(test_gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_pixels(ground_truth):\n",
    "    # Get unique labels and their counts\n",
    "    unique_labels, counts = np.unique(ground_truth, return_counts=True)\n",
    "    \n",
    "    # Create a dictionary to store label-wise pixel counts\n",
    "    label_pixel_counts = dict(zip(unique_labels, counts))\n",
    "    \n",
    "    return label_pixel_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-wise pixel counts:{-1: 409001638, 0: 107710351, 1: 25910981, 2: 36936035, 3: 23104175}\n"
     ]
    }
   ],
   "source": [
    "label_pixel_counts = count_label_pixels(test_ground_truth_image)\n",
    "print(f\"Label-wise pixel counts:{label_pixel_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_pixels_within_range(ground_truth, labels, pixels_per_class, x_range, y_range, z_range):\n",
    "    selected_pixels = {}\n",
    "\n",
    "    for label in labels:\n",
    "        # Get the coordinates where ground truth equals the label\n",
    "        coords = np.argwhere(ground_truth == label)\n",
    "        \n",
    "        # Filter coordinates based on the specified range\n",
    "        x_in_range = (coords[:, 0] >= x_range[0]) & (coords[:, 0] <= x_range[1])\n",
    "        y_in_range = (coords[:, 1] >= y_range[0]) & (coords[:, 1] <= y_range[1])\n",
    "        z_in_range = (coords[:, 2] >= z_range[0]) & (coords[:, 2] <= z_range[1])\n",
    "        \n",
    "        # Keep only the coordinates that satisfy all range conditions\n",
    "        filtered_coords = coords[x_in_range & y_in_range & z_in_range]\n",
    "        \n",
    "        # Check if there are enough pixels for the current label after filtering\n",
    "        if len(filtered_coords) < pixels_per_class:\n",
    "            raise ValueError(f\"Not enough pixels for label {label} within the specified range. Found {len(filtered_coords)}, required {pixels_per_class}\")\n",
    "        \n",
    "        # Randomly select pixels_per_class coordinates from filtered_coords\n",
    "        chosen_indices = np.random.choice(len(filtered_coords), pixels_per_class, replace=False)\n",
    "        chosen_coords = filtered_coords[chosen_indices]\n",
    "        \n",
    "        # Store selected coordinates for the label\n",
    "        selected_pixels[label] = chosen_coords\n",
    "\n",
    "    return selected_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_of_interest = [0, 1, 2, 3]\n",
    "z , y, x = test_images.shape\n",
    "x_range = (64, x - 64)\n",
    "y_range = (64, y - 64)\n",
    "z_range = (64, z - 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pixel_coords = select_random_pixels_within_range(test_ground_truth_image, labels_of_interest, pixels_per_class=256, x_range=x_range, y_range=y_range, z_range=z_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [[ 580   82  605]\n",
      " [ 646  414  343]\n",
      " [ 437  162  610]\n",
      " [ 556  262  230]\n",
      " [ 973  323  558]\n",
      " [ 578  219  219]\n",
      " [ 683  478  619]\n",
      " [ 784  440  523]\n",
      " [ 889  395  328]\n",
      " [ 393  456  464]\n",
      " [ 675  415  696]\n",
      " [ 839  337  367]\n",
      " [ 691  155  662]\n",
      " [ 212  293  559]\n",
      " [ 546  390  263]\n",
      " [ 428  180  681]\n",
      " [ 490  252  800]\n",
      " [ 299  271  883]\n",
      " [ 367  201  463]\n",
      " [ 157  313  760]\n",
      " [ 294  131  505]\n",
      " [ 666  201  196]\n",
      " [ 593  376  827]\n",
      " [ 215  392  561]\n",
      " [ 591  160  396]\n",
      " [ 583  179  595]\n",
      " [ 867  300  898]\n",
      " [ 623  310  258]\n",
      " [ 368  211  937]\n",
      " [ 829  450  412]\n",
      " [ 780  353  523]\n",
      " [ 106  306  882]\n",
      " [ 722  300  621]\n",
      " [ 788  367  521]\n",
      " [ 572  468  392]\n",
      " [ 421  102  540]\n",
      " [ 758  293  109]\n",
      " [ 749  481  556]\n",
      " [ 425  151  914]\n",
      " [ 735  295  587]\n",
      " [1004  382  661]\n",
      " [ 877  287  655]\n",
      " [ 308  363  454]\n",
      " [ 310  210  947]\n",
      " [ 711  374  906]\n",
      " [ 431  237  344]\n",
      " [ 876  354  174]\n",
      " [ 709  418  202]\n",
      " [ 468  416  415]\n",
      " [ 670  387  396]\n",
      " [ 506  190  305]\n",
      " [ 621  211  873]\n",
      " [  70  334  834]\n",
      " [ 911  269  546]\n",
      " [ 684  289  144]\n",
      " [ 755  370  832]\n",
      " [ 617  211  885]\n",
      " [ 690  119  644]\n",
      " [ 707  266  236]\n",
      " [ 388  476  619]\n",
      " [ 602  197  281]\n",
      " [ 511  228  932]\n",
      " [ 605  261  142]\n",
      " [ 766  239  847]\n",
      " [ 910  344  402]\n",
      " [ 307  340  406]\n",
      " [ 662  380  818]\n",
      " [ 363  438  869]\n",
      " [ 632  109  736]\n",
      " [ 899  412  734]\n",
      " [ 289  179  555]\n",
      " [ 741  370  881]\n",
      " [ 635  254  287]\n",
      " [ 552  475  482]\n",
      " [ 325  193  934]\n",
      " [ 689  265  641]\n",
      " [ 905  377  461]\n",
      " [ 590  224  355]\n",
      " [ 734  280  822]\n",
      " [ 340  225  941]\n",
      " [ 819  270  509]\n",
      " [ 517  466  670]\n",
      " [ 867  411  398]\n",
      " [ 743  281  137]\n",
      " [ 691  201  213]\n",
      " [ 726  405  644]\n",
      " [ 424  464  693]\n",
      " [ 739  309  512]\n",
      " [ 462  130  875]\n",
      " [ 684  402  345]\n",
      " [ 227  381  535]\n",
      " [ 848  284  918]\n",
      " [ 182  380  714]\n",
      " [ 733  207  505]\n",
      " [ 832  331  479]\n",
      " [ 263  379  880]\n",
      " [ 634  278  693]\n",
      " [ 815  327  128]\n",
      " [ 634  108  595]\n",
      " [ 708  249  359]\n",
      " [ 662  446  411]\n",
      " [ 753  381  460]\n",
      " [ 632  210  307]\n",
      " [ 344  208  273]\n",
      " [ 850  269  896]\n",
      " [ 755  282  482]\n",
      " [ 546  260  292]\n",
      " [ 884  290  130]\n",
      " [ 346  218  688]\n",
      " [ 335  114  512]\n",
      " [ 495  173  886]\n",
      " [ 770  268  239]\n",
      " [ 679  214  322]\n",
      " [ 228  311  684]\n",
      " [ 388  224  916]\n",
      " [ 790  298  870]\n",
      " [ 731  359  483]\n",
      " [ 893  302  623]\n",
      " [ 309  317  821]\n",
      " [ 869  403  514]\n",
      " [ 565  328  271]\n",
      " [ 369  261  374]\n",
      " [ 640  397  259]\n",
      " [ 689  419  506]\n",
      " [ 745  262  466]\n",
      " [ 785  320   76]\n",
      " [ 279  263  522]\n",
      " [ 548  207  544]\n",
      " [ 746  348  868]\n",
      " [ 420  148  488]\n",
      " [ 756  297  482]\n",
      " [ 552  318  948]\n",
      " [ 346   79  690]\n",
      " [ 241  394  858]\n",
      " [ 656  297  606]\n",
      " [ 338  317  900]\n",
      " [ 147  274  886]\n",
      " [ 354  186  873]\n",
      " [ 782  362  145]\n",
      " [ 670  413  327]\n",
      " [ 607  173  802]\n",
      " [ 747  420  895]\n",
      " [ 407  279  192]\n",
      " [ 631  239  748]\n",
      " [ 302  262  635]\n",
      " [ 885  350  452]\n",
      " [ 581  433  304]\n",
      " [ 356  211  752]\n",
      " [ 489  240  759]\n",
      " [ 142  324  840]\n",
      " [ 293  349  867]\n",
      " [ 280  410  807]\n",
      " [ 254  137  909]\n",
      " [ 572  187  284]\n",
      " [ 254  244  907]\n",
      " [ 124  301  822]\n",
      " [ 300  233  255]\n",
      " [ 635  393  381]\n",
      " [ 779  420  780]\n",
      " [ 962  416  670]\n",
      " [ 425  220  856]\n",
      " [ 541  453  362]\n",
      " [ 333  444  727]\n",
      " [ 343  380  413]\n",
      " [ 726  372  416]\n",
      " [ 637  300  409]\n",
      " [ 749  238  647]\n",
      " [ 883  292  681]\n",
      " [ 677  246  956]\n",
      " [ 918  410  458]\n",
      " [ 631  218  281]\n",
      " [ 950  372  703]\n",
      " [ 336  245  431]\n",
      " [ 425  432  794]\n",
      " [ 649  344  290]\n",
      " [ 867  259  486]\n",
      " [ 544  161  702]\n",
      " [ 153  319  779]\n",
      " [ 652  223  343]\n",
      " [ 735  223  573]\n",
      " [ 554  348  265]\n",
      " [ 745  366  146]\n",
      " [ 379  154  512]\n",
      " [ 839  309  302]\n",
      " [ 706  141  523]\n",
      " [ 310  266  520]\n",
      " [ 249  330  769]\n",
      " [ 319  432  749]\n",
      " [ 596  113  721]\n",
      " [ 865  335  881]\n",
      " [ 235  323  426]\n",
      " [ 312  323  865]\n",
      " [ 408  156  593]\n",
      " [ 590  275  312]\n",
      " [ 484  191  513]\n",
      " [ 441  142  554]\n",
      " [ 823  212  776]\n",
      " [ 410  475  755]\n",
      " [ 751  356  532]\n",
      " [ 457  124  451]\n",
      " [ 793  315  574]\n",
      " [ 715  468  840]\n",
      " [ 280  347  375]\n",
      " [ 597  319  838]\n",
      " [ 716  362  748]\n",
      " [ 307  226  839]\n",
      " [ 645  300  353]\n",
      " [ 943  302  853]\n",
      " [ 597  463  688]\n",
      " [ 147  342  746]\n",
      " [ 576  245  919]\n",
      " [ 622  205  901]\n",
      " [ 653  201  839]\n",
      " [ 344  107  950]\n",
      " [ 461  299  318]\n",
      " [ 893  339  781]\n",
      " [ 450  152  337]\n",
      " [ 276  303  419]\n",
      " [ 668  190  560]\n",
      " [ 788  365  196]\n",
      " [ 175  306  835]\n",
      " [ 236  293  458]\n",
      " [ 327  180  871]\n",
      " [ 649  446  816]\n",
      " [ 837  276   81]\n",
      " [ 197  304  602]\n",
      " [ 709  379  491]\n",
      " [ 534  372  210]\n",
      " [ 489  177  650]\n",
      " [ 183  225  947]\n",
      " [ 585  253  188]\n",
      " [ 389  370  341]\n",
      " [ 532  288  322]\n",
      " [ 870  344  566]\n",
      " [ 525  221  362]\n",
      " [ 623  218  619]\n",
      " [ 871  428  746]\n",
      " [ 766  379  531]\n",
      " [ 494  434  303]\n",
      " [ 686  411  860]\n",
      " [ 592  119  691]\n",
      " [ 700  437  618]\n",
      " [ 581  291  950]\n",
      " [ 857  267  474]\n",
      " [ 762  249  343]\n",
      " [ 630  392  478]\n",
      " [ 652  456  489]\n",
      " [ 769  329  617]\n",
      " [ 629  189  231]\n",
      " [ 663  117  755]\n",
      " [ 673  333  914]\n",
      " [ 305  252  473]\n",
      " [ 823  377  432]\n",
      " [ 673  369  682]\n",
      " [ 525  247  201]\n",
      " [ 244  444  756]]\n",
      "Label 1: [[288 423 675]\n",
      " [267 390 615]\n",
      " [598 359 650]\n",
      " [352 309 804]\n",
      " [430 395 773]\n",
      " [381 287 473]\n",
      " [588 348 736]\n",
      " [492 395 485]\n",
      " [421 411 682]\n",
      " [454 332 664]\n",
      " [566 380 719]\n",
      " [370 382 589]\n",
      " [452 355 479]\n",
      " [494 225 669]\n",
      " [629 334 566]\n",
      " [356 413 521]\n",
      " [571 326 686]\n",
      " [532 245 568]\n",
      " [430 260 745]\n",
      " [431 341 827]\n",
      " [555 372 511]\n",
      " [642 320 653]\n",
      " [511 402 457]\n",
      " [422 382 810]\n",
      " [459 321 759]\n",
      " [380 341 833]\n",
      " [447 450 524]\n",
      " [602 307 593]\n",
      " [436 302 724]\n",
      " [406 292 793]\n",
      " [473 279 739]\n",
      " [442 449 535]\n",
      " [537 284 650]\n",
      " [466 289 738]\n",
      " [419 448 556]\n",
      " [471 265 587]\n",
      " [557 339 816]\n",
      " [469 386 415]\n",
      " [517 426 463]\n",
      " [505 219 607]\n",
      " [270 363 514]\n",
      " [271 332 724]\n",
      " [524 283 735]\n",
      " [471 411 674]\n",
      " [457 409 514]\n",
      " [346 313 661]\n",
      " [526 253 590]\n",
      " [591 376 565]\n",
      " [465 312 837]\n",
      " [319 432 693]\n",
      " [542 249 648]\n",
      " [423 396 501]\n",
      " [543 382 514]\n",
      " [336 383 689]\n",
      " [382 317 580]\n",
      " [369 339 645]\n",
      " [486 299 759]\n",
      " [625 378 699]\n",
      " [538 264 589]\n",
      " [387 422 699]\n",
      " [258 377 574]\n",
      " [401 284 470]\n",
      " [497 415 429]\n",
      " [549 291 744]\n",
      " [612 377 582]\n",
      " [381 297 836]\n",
      " [488 363 497]\n",
      " [579 307 558]\n",
      " [375 378 796]\n",
      " [531 375 610]\n",
      " [447 296 532]\n",
      " [491 270 714]\n",
      " [249 337 667]\n",
      " [558 275 571]\n",
      " [517 292 859]\n",
      " [538 242 723]\n",
      " [322 295 630]\n",
      " [326 409 666]\n",
      " [432 270 571]\n",
      " [428 278 734]\n",
      " [612 282 717]\n",
      " [541 267 722]\n",
      " [337 442 610]\n",
      " [454 333 577]\n",
      " [566 374 757]\n",
      " [502 377 582]\n",
      " [373 272 504]\n",
      " [334 305 606]\n",
      " [569 381 746]\n",
      " [602 317 727]\n",
      " [609 373 776]\n",
      " [617 373 523]\n",
      " [386 302 743]\n",
      " [575 329 683]\n",
      " [387 307 804]\n",
      " [535 309 664]\n",
      " [391 361 773]\n",
      " [502 457 685]\n",
      " [485 437 609]\n",
      " [327 311 688]\n",
      " [535 469 599]\n",
      " [458 342 554]\n",
      " [588 343 676]\n",
      " [460 357 438]\n",
      " [593 296 501]\n",
      " [437 368 799]\n",
      " [519 386 456]\n",
      " [623 297 659]\n",
      " [417 423 461]\n",
      " [622 311 518]\n",
      " [455 386 652]\n",
      " [395 312 465]\n",
      " [622 295 633]\n",
      " [638 305 717]\n",
      " [458 264 541]\n",
      " [414 288 591]\n",
      " [445 246 625]\n",
      " [368 337 685]\n",
      " [520 345 744]\n",
      " [507 333 813]\n",
      " [439 435 552]\n",
      " [358 296 734]\n",
      " [367 372 501]\n",
      " [335 367 607]\n",
      " [633 364 543]\n",
      " [371 353 596]\n",
      " [419 308 859]\n",
      " [346 444 677]\n",
      " [478 333 540]\n",
      " [502 404 691]\n",
      " [494 379 481]\n",
      " [368 441 582]\n",
      " [381 383 756]\n",
      " [301 285 625]\n",
      " [541 246 594]\n",
      " [488 411 538]\n",
      " [508 276 724]\n",
      " [517 301 565]\n",
      " [668 353 672]\n",
      " [478 465 566]\n",
      " [547 385 702]\n",
      " [299 307 690]\n",
      " [332 365 757]\n",
      " [521 372 656]\n",
      " [398 408 550]\n",
      " [287 301 590]\n",
      " [484 313 460]\n",
      " [280 368 564]\n",
      " [565 281 575]\n",
      " [387 345 780]\n",
      " [318 332 605]\n",
      " [456 337 842]\n",
      " [356 245 643]\n",
      " [368 353 508]\n",
      " [367 340 493]\n",
      " [628 310 622]\n",
      " [479 435 684]\n",
      " [395 291 831]\n",
      " [355 390 499]\n",
      " [384 310 523]\n",
      " [602 325 725]\n",
      " [669 335 639]\n",
      " [531 278 751]\n",
      " [579 355 473]\n",
      " [500 421 664]\n",
      " [397 320 633]\n",
      " [437 460 566]\n",
      " [477 433 499]\n",
      " [386 296 714]\n",
      " [634 381 741]\n",
      " [531 296 808]\n",
      " [470 431 746]\n",
      " [407 333 851]\n",
      " [301 349 699]\n",
      " [590 344 547]\n",
      " [429 394 556]\n",
      " [426 287 779]\n",
      " [499 431 583]\n",
      " [296 325 504]\n",
      " [492 357 676]\n",
      " [331 333 573]\n",
      " [286 305 580]\n",
      " [618 385 723]\n",
      " [421 356 489]\n",
      " [366 273 761]\n",
      " [440 384 495]\n",
      " [309 288 530]\n",
      " [407 327 825]\n",
      " [481 411 554]\n",
      " [375 421 572]\n",
      " [342 435 589]\n",
      " [278 299 517]\n",
      " [309 389 753]\n",
      " [517 350 497]\n",
      " [488 386 637]\n",
      " [598 258 650]\n",
      " [454 386 468]\n",
      " [409 438 696]\n",
      " [443 349 740]\n",
      " [519 384 706]\n",
      " [427 354 656]\n",
      " [561 457 605]\n",
      " [516 393 724]\n",
      " [287 385 546]\n",
      " [547 315 500]\n",
      " [433 368 452]\n",
      " [541 409 746]\n",
      " [309 324 495]\n",
      " [581 310 790]\n",
      " [550 269 741]\n",
      " [562 235 661]\n",
      " [284 358 669]\n",
      " [362 263 559]\n",
      " [311 438 676]\n",
      " [294 350 652]\n",
      " [435 412 516]\n",
      " [374 448 645]\n",
      " [550 362 662]\n",
      " [460 281 864]\n",
      " [468 452 684]\n",
      " [602 287 662]\n",
      " [625 355 477]\n",
      " [543 306 540]\n",
      " [386 336 723]\n",
      " [356 370 546]\n",
      " [545 245 637]\n",
      " [598 353 556]\n",
      " [493 360 544]\n",
      " [369 402 643]\n",
      " [528 453 616]\n",
      " [449 350 720]\n",
      " [592 371 758]\n",
      " [297 341 572]\n",
      " [434 413 712]\n",
      " [482 446 645]\n",
      " [661 357 666]\n",
      " [407 306 773]\n",
      " [497 242 716]\n",
      " [440 432 589]\n",
      " [529 263 821]\n",
      " [330 399 615]\n",
      " [554 296 530]\n",
      " [378 284 596]\n",
      " [492 363 453]\n",
      " [384 378 724]\n",
      " [502 330 776]\n",
      " [551 341 667]\n",
      " [543 395 716]\n",
      " [620 329 731]\n",
      " [410 408 643]\n",
      " [486 275 752]\n",
      " [420 434 681]\n",
      " [563 429 655]\n",
      " [257 324 569]\n",
      " [543 438 636]\n",
      " [345 350 720]]\n",
      "Label 2: [[405 464 781]\n",
      " [449 460 462]\n",
      " [899 293 224]\n",
      " [511 285 297]\n",
      " [696 216 692]\n",
      " [940 303 425]\n",
      " [483  66 542]\n",
      " [633 148 709]\n",
      " [791 374 892]\n",
      " [395 175 571]\n",
      " [851 237 216]\n",
      " [779 188 723]\n",
      " [825 259 499]\n",
      " [656 351 278]\n",
      " [547 197 812]\n",
      " [789 468 642]\n",
      " [437 236 280]\n",
      " [397 233 310]\n",
      " [152 193 955]\n",
      " [832 204 427]\n",
      " [646 287 125]\n",
      " [388  98 688]\n",
      " [385 310 255]\n",
      " [618 324 308]\n",
      " [559 182 777]\n",
      " [527 287 280]\n",
      " [347 166 523]\n",
      " [533 213 935]\n",
      " [747 381 658]\n",
      " [639 380 855]\n",
      " [216 326 735]\n",
      " [669 289 682]\n",
      " [443 188 260]\n",
      " [812 376 629]\n",
      " [522 147 397]\n",
      " [884 317 427]\n",
      " [500 412 894]\n",
      " [737 148 649]\n",
      " [662 406 252]\n",
      " [527 154 849]\n",
      " [488 154 878]\n",
      " [635 121 664]\n",
      " [751 476 766]\n",
      " [854 340  99]\n",
      " [753 454 604]\n",
      " [680 314 472]\n",
      " [194 348 750]\n",
      " [848 385 665]\n",
      " [405 120 498]\n",
      " [787 415 911]\n",
      " [310 181 524]\n",
      " [243 223 434]\n",
      " [882 310 577]\n",
      " [739 232 325]\n",
      " [662 396 301]\n",
      " [571 201 350]\n",
      " [819 429 837]\n",
      " [547 146 795]\n",
      " [709 238 237]\n",
      " [775 375 144]\n",
      " [645 363 453]\n",
      " [884 419 425]\n",
      " [622 183 535]\n",
      " [452 113 421]\n",
      " [334 211 323]\n",
      " [544 223 759]\n",
      " [197 270 819]\n",
      " [667 378 419]\n",
      " [356 338 908]\n",
      " [583 199 240]\n",
      " [134 350 721]\n",
      " [387 125 455]\n",
      " [462 138 541]\n",
      " [724 396 168]\n",
      " [414 154 953]\n",
      " [239 242 461]\n",
      " [421 139 915]\n",
      " [177 324 767]\n",
      " [331 313 341]\n",
      " [821 333 173]\n",
      " [887 304 644]\n",
      " [880 331 189]\n",
      " [617 178 271]\n",
      " [388 175 867]\n",
      " [188 283 811]\n",
      " [663 317 384]\n",
      " [623 442 410]\n",
      " [863 458 653]\n",
      " [386 174 858]\n",
      " [814 199 559]\n",
      " [590 192 608]\n",
      " [372  79 555]\n",
      " [412 287 346]\n",
      " [254 266 844]\n",
      " [463 377 263]\n",
      " [873 274 821]\n",
      " [728 439 827]\n",
      " [587 204 901]\n",
      " [466  98 447]\n",
      " [940 328 656]\n",
      " [408 101 705]\n",
      " [510 474 442]\n",
      " [587 205 304]\n",
      " [797 376 137]\n",
      " [329 169 476]\n",
      " [588 195 216]\n",
      " [686 396 845]\n",
      " [394 121 939]\n",
      " [427 140 666]\n",
      " [467 326 946]\n",
      " [397 205 931]\n",
      " [896 334 127]\n",
      " [759 399 699]\n",
      " [878 313 349]\n",
      " [409  92 648]\n",
      " [829 475 700]\n",
      " [453  81 585]\n",
      " [337 287 366]\n",
      " [153 293 885]\n",
      " [552 198 299]\n",
      " [876 389 785]\n",
      " [477 394 264]\n",
      " [504 310 212]\n",
      " [895 288 393]\n",
      " [364 103 722]\n",
      " [320 338 364]\n",
      " [637 400 871]\n",
      " [749 350 108]\n",
      " [430 343 951]\n",
      " [878 380 774]\n",
      " [189 368 847]\n",
      " [871 364 756]\n",
      " [677 382 840]\n",
      " [655 279 232]\n",
      " [736 443 886]\n",
      " [245 420 790]\n",
      " [438 273 434]\n",
      " [568  90 774]\n",
      " [670 386 222]\n",
      " [534 188 302]\n",
      " [727 427 312]\n",
      " [654 180 618]\n",
      " [741 305 577]\n",
      " [716 204 287]\n",
      " [709 146 716]\n",
      " [651 359 462]\n",
      " [852 320 553]\n",
      " [498  68 533]\n",
      " [658 266 841]\n",
      " [476 193 720]\n",
      " [456 455 778]\n",
      " [414 136 957]\n",
      " [652 427 334]\n",
      " [711 197 656]\n",
      " [808 213 652]\n",
      " [899 281 589]\n",
      " [640 351 115]\n",
      " [466  88 506]\n",
      " [229 342 526]\n",
      " [535 173 285]\n",
      " [618 400 231]\n",
      " [373 137 573]\n",
      " [712 369 159]\n",
      " [766 262 558]\n",
      " [879 336 850]\n",
      " [803 443 370]\n",
      " [428 247 850]\n",
      " [256 437 635]\n",
      " [373  74 625]\n",
      " [843 401 425]\n",
      " [561 192 708]\n",
      " [312 281 438]\n",
      " [617 384 944]\n",
      " [426 305 206]\n",
      " [568 142 684]\n",
      " [236 261 858]\n",
      " [675 465 319]\n",
      " [830 229 525]\n",
      " [651 270 836]\n",
      " [349 426 483]\n",
      " [495 180 908]\n",
      " [668 230 877]\n",
      " [366 183 907]\n",
      " [785 329 728]\n",
      " [334 104 595]\n",
      " [621 471 504]\n",
      " [553 200 612]\n",
      " [364 204 387]\n",
      " [542 135 675]\n",
      " [393 171 555]\n",
      " [197 435 677]\n",
      " [634 193 329]\n",
      " [423 412 368]\n",
      " [748 390 773]\n",
      " [881 415 679]\n",
      " [932 304 374]\n",
      " [675 413 219]\n",
      " [950 310 756]\n",
      " [917 390 564]\n",
      " [752 467 449]\n",
      " [873 326 357]\n",
      " [427 119 681]\n",
      " [357 260 820]\n",
      " [854 405 303]\n",
      " [636 343 146]\n",
      " [791 379 867]\n",
      " [465 359 923]\n",
      " [850 291 374]\n",
      " [766 170 640]\n",
      " [278 247 454]\n",
      " [430 207 238]\n",
      " [311 109 582]\n",
      " [229 218 940]\n",
      " [550 218 898]\n",
      " [674 119 609]\n",
      " [743 391 204]\n",
      " [833 215 486]\n",
      " [268 239 444]\n",
      " [943 330 598]\n",
      " [688 158 755]\n",
      " [451 182 740]\n",
      " [672 156 729]\n",
      " [975 392 626]\n",
      " [647 325 496]\n",
      " [358 153 855]\n",
      " [173 417 728]\n",
      " [348 174 298]\n",
      " [587 457 314]\n",
      " [757 327 129]\n",
      " [318  76 814]\n",
      " [220 386 525]\n",
      " [253 271 598]\n",
      " [879 348 834]\n",
      " [581 449 375]\n",
      " [242 352 704]\n",
      " [439 399 911]\n",
      " [747 471 294]\n",
      " [912 263 508]\n",
      " [368 129 872]\n",
      " [763 166 601]\n",
      " [683 118 500]\n",
      " [674 218 726]\n",
      " [839 276 447]\n",
      " [388 278 263]\n",
      " [624 160 430]\n",
      " [339 191 391]\n",
      " [787 305 512]\n",
      " [890 273 527]\n",
      " [355 199 561]\n",
      " [533  65 574]\n",
      " [197 328 813]\n",
      " [614  80 677]\n",
      " [960 382 551]\n",
      " [772 326 741]\n",
      " [600 241 579]\n",
      " [960 388 630]]\n",
      "Label 3: [[794 258 776]\n",
      " [768 457 361]\n",
      " [390 192 614]\n",
      " [638 404 817]\n",
      " [587 206 862]\n",
      " [562 242 916]\n",
      " [760 313 488]\n",
      " [440 334 399]\n",
      " [766 377 213]\n",
      " [702 346 940]\n",
      " [208 308 827]\n",
      " [214 289 827]\n",
      " [691 211 652]\n",
      " [469 194 609]\n",
      " [761 351 828]\n",
      " [593 398 949]\n",
      " [683 356 255]\n",
      " [834 394 643]\n",
      " [775 382 692]\n",
      " [501  86 568]\n",
      " [592  68 722]\n",
      " [511 192 336]\n",
      " [873 277 610]\n",
      " [372 106 600]\n",
      " [344  69 778]\n",
      " [710 271 388]\n",
      " [573 123 487]\n",
      " [636 253 696]\n",
      " [860 333 781]\n",
      " [517 205 910]\n",
      " [706 338 248]\n",
      " [421 365 884]\n",
      " [798 304 352]\n",
      " [642 213 735]\n",
      " [781 313 887]\n",
      " [775 452 544]\n",
      " [500 125 558]\n",
      " [791 335 306]\n",
      " [737 225 816]\n",
      " [662 456 773]\n",
      " [654 372 427]\n",
      " [804 390 708]\n",
      " [593 234 781]\n",
      " [792 318 821]\n",
      " [409 379 837]\n",
      " [779 309 490]\n",
      " [595 113 520]\n",
      " [453 140 455]\n",
      " [380 150 934]\n",
      " [478 295 404]\n",
      " [529 100 582]\n",
      " [553 353 859]\n",
      " [795 305 124]\n",
      " [781 220 313]\n",
      " [514 201 335]\n",
      " [379 170 948]\n",
      " [590 117 547]\n",
      " [424 273 398]\n",
      " [184 312 894]\n",
      " [717 337 650]\n",
      " [631 336 893]\n",
      " [781 214 711]\n",
      " [573 185 460]\n",
      " [730 309 351]\n",
      " [476 143 449]\n",
      " [861 347 715]\n",
      " [352 231 446]\n",
      " [714 376 242]\n",
      " [825 412 585]\n",
      " [502 392 357]\n",
      " [517 121 581]\n",
      " [748 280 274]\n",
      " [328 166 946]\n",
      " [754 307 298]\n",
      " [428 219 326]\n",
      " [724 358 328]\n",
      " [452 190 633]\n",
      " [539 452 438]\n",
      " [592 141 475]\n",
      " [705 328 945]\n",
      " [425 298 428]\n",
      " [679 329 845]\n",
      " [742 289 359]\n",
      " [572 270 468]\n",
      " [609 164 520]\n",
      " [764 302 405]\n",
      " [502 416 370]\n",
      " [376 269 363]\n",
      " [219 331 903]\n",
      " [211 317 823]\n",
      " [485 163 356]\n",
      " [554 190 367]\n",
      " [449 186 403]\n",
      " [560 350 406]\n",
      " [441 235 324]\n",
      " [782 310 342]\n",
      " [297 367 775]\n",
      " [783 386 331]\n",
      " [849 289 660]\n",
      " [824 276 263]\n",
      " [745 315 185]\n",
      " [720 321 443]\n",
      " [750 451 364]\n",
      " [370 106 646]\n",
      " [757 305 266]\n",
      " [466 385 834]\n",
      " [541 154 458]\n",
      " [183 319 852]\n",
      " [810 286 280]\n",
      " [503  65 753]\n",
      " [475 355 347]\n",
      " [678 253 774]\n",
      " [560 175 646]\n",
      " [705 318 248]\n",
      " [633 201 519]\n",
      " [409 141 544]\n",
      " [717 192 624]\n",
      " [833 449 647]\n",
      " [433 183 572]\n",
      " [277 382 824]\n",
      " [470 255 831]\n",
      " [844 277 687]\n",
      " [249 405 713]\n",
      " [780 311 218]\n",
      " [783 230 397]\n",
      " [806 268 230]\n",
      " [438 259 342]\n",
      " [755 264 768]\n",
      " [666 121 437]\n",
      " [446 244 410]\n",
      " [535 304 236]\n",
      " [317 313 892]\n",
      " [728 443 424]\n",
      " [851 401 381]\n",
      " [337 230 465]\n",
      " [213 189 942]\n",
      " [513  83 626]\n",
      " [732 332 930]\n",
      " [232 337 725]\n",
      " [840 274 692]\n",
      " [440 126 496]\n",
      " [663 427 539]\n",
      " [744 299 719]\n",
      " [781 213 721]\n",
      " [786 251 304]\n",
      " [453 228 328]\n",
      " [178 313 901]\n",
      " [380 189 432]\n",
      " [220 401 758]\n",
      " [785 257 785]\n",
      " [385 261 402]\n",
      " [423 233 843]\n",
      " [514 287 449]\n",
      " [660 227 636]\n",
      " [617 415 459]\n",
      " [722 411 926]\n",
      " [617 309 182]\n",
      " [842 449 671]\n",
      " [840 428 623]\n",
      " [626 126 757]\n",
      " [483  83 795]\n",
      " [657 167 494]\n",
      " [633 239 767]\n",
      " [612 219 653]\n",
      " [729 384 243]\n",
      " [741 412 905]\n",
      " [814 295 393]\n",
      " [474 158 342]\n",
      " [383 208 877]\n",
      " [767 398 544]\n",
      " [622 260 723]\n",
      " [513  97 594]\n",
      " [523  82 636]\n",
      " [336 245 457]\n",
      " [293 360 785]\n",
      " [269 360 923]\n",
      " [733 310 442]\n",
      " [812 349 768]\n",
      " [789 290 842]\n",
      " [477 242 316]\n",
      " [751 455 531]\n",
      " [472 305 929]\n",
      " [282 296 943]\n",
      " [730 283 303]\n",
      " [549 241 940]\n",
      " [780 221 601]\n",
      " [815 302 851]\n",
      " [770 222 428]\n",
      " [732 313 394]\n",
      " [829 296 826]\n",
      " [735 260 175]\n",
      " [218 216 910]\n",
      " [317 131 948]\n",
      " [311 312 919]\n",
      " [669 254 910]\n",
      " [610 301 455]\n",
      " [422 188 596]\n",
      " [678 316 735]\n",
      " [837 301 483]\n",
      " [708 321 190]\n",
      " [522 222 889]\n",
      " [415 224 882]\n",
      " [768 425 448]\n",
      " [397 349 898]\n",
      " [772 252 197]\n",
      " [380 208 450]\n",
      " [215 345 692]\n",
      " [820 399 619]\n",
      " [730 464 504]\n",
      " [451 162 341]\n",
      " [859 354 675]\n",
      " [644 134 750]\n",
      " [445 283 375]\n",
      " [615 206 774]\n",
      " [774 253 792]\n",
      " [758 292 260]\n",
      " [569 165 596]\n",
      " [790 319 321]\n",
      " [847 416 573]\n",
      " [562 145 530]\n",
      " [698 404 917]\n",
      " [800 456 504]\n",
      " [458 384 826]\n",
      " [699 177 587]\n",
      " [620 306 823]\n",
      " [437 221 301]\n",
      " [799 227 313]\n",
      " [495 291 920]\n",
      " [876 358 658]\n",
      " [673 264 898]\n",
      " [617 216 827]\n",
      " [385  67 692]\n",
      " [258 378 801]\n",
      " [876 296 491]\n",
      " [488 187 317]\n",
      " [841 372 629]\n",
      " [247 306 837]\n",
      " [546 336 911]\n",
      " [481 406 360]\n",
      " [427 298 408]\n",
      " [788 306 444]\n",
      " [597 370 348]\n",
      " [588 335 248]\n",
      " [505 126 462]\n",
      " [480 338 251]\n",
      " [563 240 902]\n",
      " [660 350 396]\n",
      " [842 285 240]\n",
      " [520 205 342]\n",
      " [596  98 563]\n",
      " [778 414 662]\n",
      " [624 125 594]\n",
      " [489 160 497]\n",
      " [319 266 840]\n",
      " [307 323 919]\n",
      " [500 412 357]]\n"
     ]
    }
   ],
   "source": [
    "for label, coords in selected_pixel_coords.items():\n",
    "    print(f\"Label {label}: {coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_as_pickle(selected_pixel_coords, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(selected_pixel_coords, f)\n",
    "\n",
    "# Usage\n",
    "save_as_pickle(selected_pixel_coords, 'selected_pixel_coords.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image, coords, patch_size=64):\n",
    "    half_size = patch_size // 2\n",
    "    patches = []\n",
    "\n",
    "    # Get the shape of the image\n",
    "    z_max, y_max, x_max = image.shape\n",
    "\n",
    "    for coord in coords:\n",
    "        z, y, x = coord\n",
    "\n",
    "        # Calculate the boundaries of the patch\n",
    "        x_start = max(0, x - half_size)\n",
    "        x_end = min(x_max, x + half_size)\n",
    "        y_start = max(0, y - half_size)\n",
    "        y_end = min(y_max, y + half_size)\n",
    "        z_start = max(0, z - 4)\n",
    "        z_end = min(z_max, z + 4)\n",
    "        \n",
    "        # Extract the patch from the image\n",
    "        patch = image[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        # Check if the patch is the required size, otherwise pad with zeros\n",
    "        if patch.shape != (8, patch_size, patch_size):\n",
    "            print(\"something is wrong\")\n",
    "\n",
    "        \n",
    "        # Store the patch\n",
    "        patches.append(patch)\n",
    "\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches for label 0: torch.Size([256, 1, 8, 64, 64])\n",
      "Patches for label 1: torch.Size([256, 1, 8, 64, 64])\n",
      "Patches for label 2: torch.Size([256, 1, 8, 64, 64])\n",
      "Patches for label 3: torch.Size([256, 1, 8, 64, 64])\n",
      "torch.Size([4, 256, 1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "all_patches_tensors = []\n",
    "\n",
    "for label, coords in selected_pixel_coords.items():\n",
    "    patches = extract_patches(test_images, coords, patch_size=64)\n",
    "    patches_tensor = torch.tensor(patches, dtype=torch.float32).unsqueeze(1)\n",
    "    print(f\"Patches for label {label}: {patches_tensor.shape}\")  # The shape should be (256, 8, 64, 64)\n",
    "    all_patches_tensors.append(patches_tensor)\n",
    "\n",
    "combined_tensor = torch.stack(all_patches_tensors, dim=0)\n",
    "print(combined_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000 pixels with model version 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sheida.rahnamai/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "  0%|          | 0/4 [00:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m batch \u001b[38;5;241m=\u001b[39m (batch \u001b[38;5;241m-\u001b[39m data_mean) \u001b[38;5;241m/\u001b[39m data_std\n\u001b[0;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     19\u001b[0m mu_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mmean(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m\"\u001b[39m][i],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hierarchy_level)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m mu_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mu_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../models/lvae.py:219\u001b[0m, in \u001b[0;36mLadderVAE.forward\u001b[0;34m(self, x, y, x_orig)\u001b[0m\n\u001b[1;32m    217\u001b[0m bu_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottomup_pass(x_pad)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Top-down inference/generation\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m out, td_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopdown_pass(bu_values)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Restore original image size\u001b[39;00m\n\u001b[1;32m    221\u001b[0m out \u001b[38;5;241m=\u001b[39m crop_img_tensor(out, img_size)\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../models/lvae.py:344\u001b[0m, in \u001b[0;36mLadderVAE.topdown_pass\u001b[0;34m(self, bu_values, n_img_prior, mode_layers, constant_layers, forced_latent)\u001b[0m\n\u001b[1;32m    341\u001b[0m skip_input \u001b[38;5;241m=\u001b[39m out  \u001b[38;5;66;03m# TODO or out_pre_residual? or both?\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# Full top-down layer, including sampling and deterministic part\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m out, out_pre_residual, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_down_layers[i](\n\u001b[1;32m    345\u001b[0m     out,\n\u001b[1;32m    346\u001b[0m     skip_connection_input\u001b[38;5;241m=\u001b[39mskip_input,\n\u001b[1;32m    347\u001b[0m     inference_mode\u001b[38;5;241m=\u001b[39minference_mode,\n\u001b[1;32m    348\u001b[0m     bu_value\u001b[38;5;241m=\u001b[39mbu_value,\n\u001b[1;32m    349\u001b[0m     n_img_prior\u001b[38;5;241m=\u001b[39mn_img_prior,\n\u001b[1;32m    350\u001b[0m     use_mode\u001b[38;5;241m=\u001b[39muse_mode,\n\u001b[1;32m    351\u001b[0m     force_constant_output\u001b[38;5;241m=\u001b[39mconstant_out,\n\u001b[1;32m    352\u001b[0m     forced_latent\u001b[38;5;241m=\u001b[39mforced_latent[i],\n\u001b[1;32m    353\u001b[0m     mode_pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode_pred,\n\u001b[1;32m    354\u001b[0m     use_uncond_mode\u001b[38;5;241m=\u001b[39muse_uncond_mode\n\u001b[1;32m    355\u001b[0m )\n\u001b[1;32m    356\u001b[0m z[i] \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# sampled variable at this layer (batch, ch, h, w)\u001b[39;00m\n\u001b[1;32m    357\u001b[0m kl[i] \u001b[38;5;241m=\u001b[39m aux[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_samplewise\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# (batch, )\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../models/lvae_layers.py:189\u001b[0m, in \u001b[0;36mTopDownLayer.forward\u001b[0;34m(self, input_, skip_connection_input, inference_mode, bu_value, n_img_prior, forced_latent, use_mode, force_constant_output, mode_pred, use_uncond_mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m x_pre_residual \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Last top-down block (sequence of residual blocks)\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic_block(x)\n\u001b[1;32m    191\u001b[0m keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_samplewise\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_spatial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprob_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprob_q\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    192\u001b[0m data \u001b[38;5;241m=\u001b[39m {k: data_stoch[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys}\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../models/lvae_layers.py:331\u001b[0m, in \u001b[0;36mResBlockWithResampling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_conv(x)\n\u001b[0;32m--> 331\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres(x)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_conv(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../lib/nn.py:112\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock, inp) \u001b[38;5;241m+\u001b[39m inp\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:36\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:487\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointFunction\u001b[38;5;241m.\u001b[39mapply(function, preserve, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    490\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    491\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/utils/checkpoint.py:262\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    259\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m run_function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/HDN/examples/3D/Pixel_Noise/../../../lib/nn.py:138\u001b[0m, in \u001b[0;36mGateLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[1;32m    137\u001b[0m x, gate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(x, \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlin(x)  \u001b[38;5;66;03m# TODO remove this?\u001b[39;00m\n\u001b[1;32m    139\u001b[0m gate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(gate)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m gate\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/modules/activation.py:523\u001b[0m, in \u001b[0;36mELU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/miniconda3/envs/emseg/lib/python3.12/site-packages/torch/nn/functional.py:1591\u001b[0m, in \u001b[0;36melu\u001b[0;34m(input, alpha, inplace)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB. GPU "
     ]
    }
   ],
   "source": [
    "model_dir = \"/group/jug/Sheida/HVAE/3D/\"\n",
    "model_versions = [4,5,6,7,8]\n",
    "batch_size = 256\n",
    "for model_v in model_versions:\n",
    "    model = torch.load(model_dir+'v0'+str(model_v)+\"/model/3D_HVAE_best_vae.net\")\n",
    "    data_mean = model.data_mean\n",
    "    data_std = model.data_std\n",
    "    model.mode_pred = True\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    print(f\"Processing 1000 pixels with model version {model_v}\")\n",
    "    index = 0 \n",
    "    all_mus = np.zeros((batch_size, 43008), dtype=np.float16)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(combined_tensor):\n",
    "            batch = batch.to(device)\n",
    "            batch = (batch - data_mean) / data_std\n",
    "            output = model(batch)\n",
    "            mu_test = torch.cat([torch.mean(output[\"mu\"][i],dim=2).reshape(batch_size, -1) for i in range(hierarchy_level)], dim=1)\n",
    "            mu_test = np.array(mu_test.cpu().numpy())\n",
    "            all_mus[index:index+batch_size] = mu_test\n",
    "            index += batch_size\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_mus)\n",
    "    cluster_labels = cluster_labels.reshape(4, 256)\n",
    "    tiff.imwrite(f\"{model_dir}v0{model_v}/1000pixels.tif\", cluster_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
