{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('/home/sheida.rahnamai/GIT/HDN/')\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "# from lib.dataloader import CustomTestDataset\n",
    "from boilerplate.dataloader import Custom3DTestDataset\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from boilerplate import boilerplate\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch.nn.functional import unfold\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "dist_metric = ['cosine']\n",
    "\n",
    "num_clusters = 4\n",
    "patch_size = (8,64,64)\n",
    "centre_size = 5\n",
    "n_channel = 32\n",
    "hierarchy_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/group/jug/Sheida/pancreatic beta cells/download/\"\n",
    "\n",
    "One_test_image = ['high_c4']\n",
    "\n",
    "# Load test image\n",
    "test_img_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_source.tif\")\n",
    "test_images = tiff.imread(test_img_path)\n",
    "\n",
    "# Print loaded test images paths\n",
    "print(\"Test image loaded from path:\")\n",
    "print(test_img_path)\n",
    "\n",
    "# Load test ground truth images\n",
    "test_gt_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_gt.tif\")\n",
    "test_ground_truth_image = tiff.imread(test_gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(test_images[500])\n",
    "ax[0].set_title(\"Test image\")\n",
    "ax[1].imshow(test_ground_truth_image[500])\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(test_images[600])\n",
    "ax[0].set_title(\"Test image\")\n",
    "ax[1].imshow(test_ground_truth_image[600])\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(test_images[700])\n",
    "ax[0].set_title(\"Test image\")\n",
    "ax[1].imshow(test_ground_truth_image[700])\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/group/jug/Sheida/HVAE/3D/\"\n",
    "img_idx = [500,600,700]\n",
    "model_versions = [4,5,6,7,8]\n",
    "batch_size = 256\n",
    "for test_index in img_idx:\n",
    "    print(\"Processing test dataset\")\n",
    "    test_dataset = Custom3DTestDataset(test_images, patch_size=patch_size, index=test_index)\n",
    "    print(\"Test dataset loaded. Processing test dataloader\")\n",
    "    dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    for model_v in model_versions:\n",
    "        model = torch.load(model_dir+'v0'+str(model_v)+\"/model/3D_HVAE_best_vae.net\")\n",
    "        data_mean = model.data_mean\n",
    "        data_std = model.data_std\n",
    "        model.mode_pred = True\n",
    "        model.eval()\n",
    "        device = model.device\n",
    "        print(f\"Processing image slice {test_index} with model version {model_v}\")\n",
    "        index = 0 \n",
    "        all_mus = np.zeros(((test_dataset.height * test_dataset.width), 43008), dtype=np.float16)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader):\n",
    "                batch = batch.to(device)\n",
    "                batch = (batch - data_mean) / data_std\n",
    "                output = model(batch)\n",
    "                mu_test = torch.cat([torch.mean(output[\"mu\"][i],dim=2).reshape(batch_size, -1) for i in range(hierarchy_level)], dim=1)\n",
    "                mu_test = np.array(mu_test.cpu().numpy())\n",
    "                all_mus[index:index+batch_size] = mu_test\n",
    "                index += batch_size\n",
    "\n",
    "        # Perform K-means clustering\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(all_mus)\n",
    "        clusters = cluster_labels.reshape(test_dataset.height, test_dataset.width)\n",
    "        tiff.imwrite(f\"{model_dir}v0{model_v}/{test_index}.tif\", clusters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
