{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tifffile import imread, imwrite\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LadderVAE(\n",
       "  (first_bottom_up): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): BottomUpDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (top_down_layers): ModuleList(\n",
       "    (0-3): 4 x TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_p): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (merge): MergeLayer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (skip_connection_merger): SkipConnectionMerger(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottom_up_layers): ModuleList(\n",
       "    (0-4): 5 x BottomUpLayer(\n",
       "      (net): Sequential(\n",
       "        (0): BottomUpDeterministicResBlock(\n",
       "          (pre_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_top_down): Sequential(\n",
       "    (0): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (parameter_net): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/group/jug/Sheida/pancreatic beta cells/download/high_c1/\"\n",
    "patch_size = 64\n",
    "model = torch.load(\"/group/jug/Sheida/HDN models/13122023/HDN Muller_best_vae.net\")\n",
    "model.mode_pred=True\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(mu):\n",
    "    slice_features_mu = mu.astype(float)\n",
    "    feature_flatten_mu = slice_features_mu.reshape(160, -1).T\n",
    "    K_CENTRE = 8\n",
    "    kmeans_mu = KMeans(\n",
    "        n_clusters=K_CENTRE, init='k-means++', n_init=10,\n",
    "        max_iter=1000, random_state=777\n",
    "    )\n",
    "    kmeans_mu.fit(feature_flatten_mu)\n",
    "    labels_mu = kmeans_mu.predict(feature_flatten_mu)\n",
    "    return labels_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_tensor(img,model,device):\n",
    "    '''\n",
    "    Normalizes tensor with mean and std.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: array\n",
    "        Image.\n",
    "    model: Hierarchical DivNoising model\n",
    "    device: GPU device.\n",
    "    '''\n",
    "    test_images = torch.from_numpy(img.copy()).to(device)\n",
    "    data_mean = model.data_mean\n",
    "    data_std = model.data_std\n",
    "    test_images = (test_images-data_mean)/data_std\n",
    "    return test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tiled(img):\n",
    "    out = np.zeros([img.shape[0]+61, img.shape[1]+60])\n",
    "    # make mirror margin of 2d image\n",
    "    for i in range(30):\n",
    "        out[i,30:30+img.shape[1]] = img[30-i-1,:]\n",
    "        out[30:30+img.shape[0],30:30+img.shape[1]] = img\n",
    "        out[30+img.shape[0]+i,30:30+img.shape[1]] = img[img.shape[0]-i-1,:]\n",
    "    out[img.shape[0]+60,30:30+img.shape[1]] = img[img.shape[0]-31,:]\n",
    "    for i in range(30):\n",
    "        out[:,i] = out[:,60-i-1]\n",
    "        out[:, 30+img.shape[1]+i] = out[:, 30+img.shape[1]-i-1]\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(path+\"data/test/high_c1_source_661.tif\")\n",
    "tiled = make_tiled(img)\n",
    "img_height,img_width = 700,760\n",
    "img = get_normalized_tensor(tiled,model,device)\n",
    "output = np.zeros((160, 700, 760))\n",
    "for i in tqdm(range(0, img_height, 4)):\n",
    "    for j in range(0, img_width, 4):\n",
    "        img_t = img[i:i+64,j:j+64]\n",
    "        image_sample = img_t.view(1,1,64,64)\n",
    "        image_sample = image_sample.to(device=device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            sample = model(image_sample)\n",
    "            mus = sample['mu']\n",
    "            output[:32,i:i+4,j:j+4] = sample['mu'][0][0].cpu().numpy().repeat(2,axis=1).repeat(2,axis=2)[:,30:34,30:34]\n",
    "            output[32:64,i:i+4,j:j+4] = sample['mu'][1][0].cpu().numpy().repeat(4,axis=1).repeat(4,axis=2)[:,30:34,30:34]\n",
    "            output[64:96,i:i+4,j:j+4] = sample['mu'][2][0].cpu().numpy().repeat(8,axis=1).repeat(8,axis=2)[:,30:34,30:34]\n",
    "            output[96:128,i:i+4,j:j+4] = sample['mu'][3][0].cpu().numpy().repeat(16,axis=1).repeat(16,axis=2)[:,30:34,30:34]\n",
    "            output[128:160,i:i+4,j:j+4] = sample['mu'][4][0].cpu().numpy().repeat(32,axis=1).repeat(32,axis=2)[:,30:34,30:34]\n",
    "clusters = clustering(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [28:19<00:00,  9.71s/it]\n"
     ]
    }
   ],
   "source": [
    "img = imread(path+\"data/test/high_c1_source_661.tif\")\n",
    "tiled = make_tiled(img)\n",
    "img_height,img_width = 700,760\n",
    "img = get_normalized_tensor(tiled,model,device)\n",
    "output = np.zeros((160, 700, 760))\n",
    "for i in tqdm(range(0, img_height, 4)):\n",
    "    for j in range(0, img_width, 4):\n",
    "        img_t = img[i:i+64,j:j+64]\n",
    "        image_sample = img_t.view(1,1,64,64)\n",
    "        image_sample = image_sample.to(device=device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            sample = model(image_sample)\n",
    "            mus = sample['mu']\n",
    "            output[:32,i:i+4,j:j+4] = sample['mu'][0][0].cpu().numpy()[:,14:18,14:18]\n",
    "            output[32:64,i:i+4,j:j+4] = sample['mu'][1][0].cpu().numpy()[:,6:10,6:10]\n",
    "            output[64:96,i:i+4,j:j+4] = sample['mu'][2][0].cpu().numpy()[:,2:6,2:6]\n",
    "            output[96:128,i:i+4,j:j+4] = sample['mu'][3][0].cpu().numpy()\n",
    "            output[128:160,i:i+4,j:j+4] = sample['mu'][4][0].cpu().numpy().repeat(2,axis=1).repeat(2,axis=2)\n",
    "clusters = clustering(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite(path+\"x.tif\", clusters.reshape(700, 760))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n",
      "(160, 768, 704)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m image_sample \u001b[39m=\u001b[39m image_sample\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     sample \u001b[39m=\u001b[39m model(image_sample)\n\u001b[1;32m     10\u001b[0m     mus \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mmu\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m160\u001b[39m, \u001b[39m768\u001b[39m, \u001b[39m704\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../models/lvae.py:224\u001b[0m, in \u001b[0;36mLadderVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m     cl_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    223\u001b[0m \u001b[39melse\u001b[39;00m:            \n\u001b[0;32m--> 224\u001b[0m     cl_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor([\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode_pred \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# kl[i] for each i has length batch_size\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# resulting kl shape: (batch_size, layers)\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     kl \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([kl_layer\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m kl_layer \u001b[39min\u001b[39;00m td_data[\u001b[39m'\u001b[39m\u001b[39mkl\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m    230\u001b[0m                    dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = glob(path+\"data/test/high_c1_source_31.tif\")\n",
    "img_height,img_width = 699, 760\n",
    "for i in files:\n",
    "    img = imread(i)\n",
    "    img_t = get_normalized_tensor(img,model,device)\n",
    "    image_sample = img_t.view(1,1,img_height,img_width)\n",
    "    image_sample = image_sample.to(device=device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        sample = model(image_sample)\n",
    "        mus = sample['mu']\n",
    "        output = np.zeros((160, 768, 704))\n",
    "\n",
    "        print(output.shape)\n",
    "\n",
    "        for idx in range(len(sample['mu'])):\n",
    "            mu = sample['mu'][idx][0].cpu().numpy()\n",
    "            # print(mu.shape)\n",
    "            # output = clustering(idx, mu)\n",
    "            # print(i)\n",
    "            # imwrite(path+\"label_model_21012024/k = 8/\"+str(idx+1)+\"/\"+i[i.rfind(\"/\"):i.rfind(\".\")]+\".tif\", output.reshape(22*(2**(4-idx)), 24*(2**(4-idx))))\n",
    "            # plt.imshow(output.reshape(22*(2**(4-idx)), 24*(2**(4-idx))))\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
