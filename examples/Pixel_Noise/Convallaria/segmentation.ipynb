{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('/home/sheida.rahnamai/GIT/HDN/')\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "import hdbscan as hd\n",
    "from hdbscan import prediction\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from collections import Counter\n",
    "from openTSNE import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "# %reload lib.plotting \n",
    "from lib import plotting as p\n",
    "from lib import dataprep as dp\n",
    "import random\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from lib.evaluation import FeatureExtractor\n",
    "# from lib.dataloader import CustomTestDataset\n",
    "from lib.dataloader import CustomDataset\n",
    "import tifffile as tiff\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from boilerplate import boilerplate\n",
    "from importlib import reload\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as mcolors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(p)\n",
    "from lib import plotting as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "patch_size = 64\n",
    "sample_size = 350\n",
    "centre_size = 4\n",
    "n_channel = 32\n",
    "hierarchy_level = 3\n",
    "pad_size = (patch_size - centre_size) // 2\n",
    "model_dir = \"/group/jug/Sheida/HVAE/cl_w_bg_v0/\"\n",
    "# model_dir = \"/group/jug/Sheida/HVAE/Hyperparameter_search/legendary-violet-547-2nd-cl1e-3_kl1/\"\n",
    "model = torch.load(model_dir+\"model/HVAE_best_vae.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading train data\n",
    "### Sample from different classes\n",
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "\n",
    "data_dir = \"/localscratch/data/\"\n",
    "Three_train_images = ['high_c1', 'high_c2', 'high_c3']\n",
    "\n",
    "# Load source images\n",
    "train_img_paths = [os.path.join(data_dir, img, f\"{img}_source.tif\") for img in Three_train_images]\n",
    "images = {img: tiff.imread(path) for img, path in zip(Three_train_images, train_img_paths)}\n",
    "\n",
    "# Print loaded train images paths\n",
    "print(\"Train images loaded from paths:\")\n",
    "for img, path in zip(Three_train_images, train_img_paths):\n",
    "   print(path)\n",
    "\n",
    "labels = {}\n",
    "# Load ground truth images\n",
    "for img in Three_train_images:\n",
    "   gt_path = os.path.join(data_dir, img, f\"{img}_gt.tif\")\n",
    "   labels[img] = tiff.imread(gt_path)\n",
    "\n",
    "# Initialize dictionaries for the split data\n",
    "train_images = {}\n",
    "val_images = {}\n",
    "train_labels = {}\n",
    "val_labels = {}\n",
    "\n",
    "keys = ['high_c1', 'high_c2', 'high_c3']\n",
    "\n",
    "for key in tqdm(keys, desc='Splitting data'):\n",
    "   filtered_image, filtered_label = boilerplate._filter_slices(images[key], labels[key])\n",
    "   train_image, val_image, train_label, val_label = boilerplate._split_slices(\n",
    "      filtered_image, filtered_label\n",
    "   )\n",
    "   train_images[key] = train_image\n",
    "   val_images[key] = val_image\n",
    "   train_labels[key] = train_label\n",
    "   val_labels[key] = val_label\n",
    "\n",
    "# compute mean and std of the data\n",
    "all_elements = np.concatenate([train_images[key].flatten() for key in keys])\n",
    "data_mean = np.mean(all_elements)\n",
    "data_std = np.std(all_elements)\n",
    "\n",
    "# normalizing the data\n",
    "for key in tqdm(keys, 'Normalizing data'):\n",
    "   train_images[key] = (train_images[key] - data_mean) / data_std\n",
    "   val_images[key] = (val_images[key] - data_mean) / data_std\n",
    "\n",
    "train_set = CustomDataset(train_images, train_labels)\n",
    "val_set = CustomDataset(val_images, val_labels)\n",
    "\n",
    "One_test_image = ['high_c4']\n",
    "\n",
    "# Load test image\n",
    "test_img_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_source.tif\")\n",
    "test_image = tiff.imread(test_img_path)\n",
    "\n",
    "# Print loaded test images paths\n",
    "print(\"Test image loaded from path:\")\n",
    "print(test_img_path)\n",
    "\n",
    "# Load test ground truth images\n",
    "test_gt_path = os.path.join(data_dir, One_test_image[0], f\"{One_test_image[0]}_gt.tif\")\n",
    "test_ground_truth_image = tiff.imread(test_gt_path)\n",
    "\n",
    "bg_indices = random.sample(train_set.patches_by_label[0],sample_size)\n",
    "nucleus_indices = random.sample(train_set.patches_by_label[1],sample_size)\n",
    "granule_indices = random.sample(train_set.patches_by_label[2],sample_size)\n",
    "mito_indices = random.sample(train_set.patches_by_label[3],sample_size)\n",
    "\n",
    "bg_samples, bg_cls, bg_lbl = train_set[bg_indices]\n",
    "nucleus_samples, nucleus_cls, nucleus_lbl = train_set[nucleus_indices]\n",
    "granule_samples, granule_cls, granule_lbl = train_set[granule_indices]\n",
    "mito_samples, mito_cls, mito_lbl = train_set[mito_indices]\n",
    "\n",
    "bg_samples = bg_samples.squeeze(1)\n",
    "bg_lbl = bg_lbl.squeeze(1)\n",
    "nucleus_samples = nucleus_samples.squeeze(1)\n",
    "nucleus_lbl = nucleus_lbl.squeeze(1)\n",
    "granule_samples = granule_samples.squeeze(1)\n",
    "granule_lbl = granule_lbl.squeeze(1)\n",
    "mito_samples = mito_samples.squeeze(1)\n",
    "mito_lbl = mito_lbl.squeeze(1)\n",
    "\n",
    "#test data\n",
    "\n",
    "test_images = (test_image-data_mean)/data_std\n",
    "\n",
    "test_slice = test_images[626]\n",
    "test_slice_lbl = test_ground_truth_image[626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = torch.cat([bg_samples, nucleus_samples, granule_samples, mito_samples], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mode_pred = True\n",
    "model.eval()\n",
    "device = model.device\n",
    "with torch.no_grad():\n",
    "    train_batch = train_batch.to(device=device, dtype=torch.float)\n",
    "    train_batch = train_batch.reshape(-1, 1, patch_size, patch_size)\n",
    "    output = model(train_batch, train_batch, train_batch, model_layers=[i for i in range(hierarchy_level)])\n",
    "    mus = output[\"mu\"]\n",
    "    # feature_map = [mus[i].flatten() for i in range(len(mus))]\n",
    "    # feature_map = np.array(torch.cat(feature_map,dim=-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mu[0].shape, mu[1].shape, mu[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot_w_b((test_slice, 'Training patch', False),\\\n",
    "        (test_slice_lbl, 'Ground truth label', False),\\\n",
    "        plot_types=['imshow', 'imshow_l'],\\\n",
    "        box_size = 10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, k, l = np.random.randint(0, sample_size, 4)\n",
    "p.plot_w_b((bg_samples[i], 'Training patch', (pad_size, pad_size, centre_size)),\\\n",
    "        (bg_lbl[i], 'Ground truth label', (pad_size, pad_size, centre_size)),\\\n",
    "        (nucleus_samples[j], 'Training patch', (pad_size, pad_size, centre_size)),\\\n",
    "        (nucleus_lbl[j], 'Ground truth label', (pad_size, pad_size, centre_size)),\\\n",
    "        (granule_samples[k], 'Training patch', (pad_size, pad_size, centre_size)),\\\n",
    "        (granule_lbl[k], 'Ground truth label', (pad_size, pad_size, centre_size)),\\\n",
    "        (mito_samples[l], 'Training patch', (pad_size, pad_size, centre_size)),\\\n",
    "        (mito_lbl[l], 'Ground truth label', (pad_size, pad_size, centre_size)),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l', 'imshow', 'imshow_l', 'imshow', 'imshow_l']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting latent space from Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_mu, nuc_mu, gra_mu, mito_mu = np.empty((0, 43008)), np.empty((0, 43008)), np.empty((0, 43008)), np.empty((0, 43008))\n",
    "FE = FeatureExtractor(model, patch_size, centre_size)\n",
    "for idx in range(sample_size):\n",
    "    mu = FE.get_feature_maps(bg_samples[idx])\n",
    "    bg_mu = np.vstack([bg_mu, mu])\n",
    "    mu = FE.get_feature_maps(nucleus_samples[idx])\n",
    "    nuc_mu = np.vstack([nuc_mu, mu])\n",
    "    mu = FE.get_feature_maps(granule_samples[idx])\n",
    "    gra_mu = np.vstack([gra_mu, mu])\n",
    "    mu = FE.get_feature_maps(mito_samples[idx])\n",
    "    mito_mu = np.vstack([mito_mu, mu])\n",
    "train_mu = np.concatenate((bg_mu, nuc_mu, gra_mu, mito_mu), axis=0)\n",
    "train_labels = np.array([0] * sample_size + [1] * sample_size + [2] * sample_size + [3] * sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(image, labels, cls, patch_size):\n",
    "    while True: \n",
    "        patch, label, y, x = dp.get_random_patch(image, labels, patch_size)\n",
    "        centre = label[pad_size:pad_size+centre_size,pad_size:pad_size+centre_size]\n",
    "        if cls in centre and np.unique(centre).size == 1:\n",
    "                return patch, label, y, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_patch, bg_label, y, x = get_patch(test_slice, test_slice_lbl, 0, patch_size)\n",
    "test_mu_bg = FE.get_feature_maps(bg_patch)\n",
    "test_mu_bg = np.expand_dims(test_mu_bg, axis=0)\n",
    "\n",
    "p.plot_w_b( (test_slice, \"Test Image\", (y, x, patch_size)),\\\n",
    "        (test_slice_lbl, \"Ground truth label\", (y, x, patch_size)),\\\n",
    "        (bg_patch, \"Random patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (bg_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l'],\n",
    "        box_size=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc_patch, nuc_label, y, x = get_patch(test_slice, test_slice_lbl, 1, patch_size)\n",
    "test_mu_nuc = FE.get_feature_maps(nuc_patch)\n",
    "test_mu_nuc = np.expand_dims(test_mu_nuc, axis=0)\n",
    "\n",
    "p.plot_w_b( (test_slice, \"Test Image\", (y, x, patch_size)),\\\n",
    "        (test_slice_lbl, \"Ground truth label\", (y, x, patch_size)),\\\n",
    "        (nuc_patch, \"Random patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (nuc_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l'],\n",
    "        box_size=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gra_patch, gra_label, y, x = get_patch(test_slice, test_slice_lbl, 2, patch_size)\n",
    "test_mu_gra = FE.get_feature_maps(gra_patch)\n",
    "test_mu_gra = np.expand_dims(test_mu_gra, axis=0)\n",
    "\n",
    "p.plot_w_b( (test_slice, \"Test Image\", (y, x, patch_size)),\\\n",
    "        (test_slice_lbl, \"Ground truth label\", (y, x, patch_size)),\\\n",
    "        (gra_patch, \"Random patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (gra_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l'],\n",
    "        box_size=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mito_patch, mito_label, y, x = get_patch(test_slice, test_slice_lbl, 3, patch_size)\n",
    "test_mu_mito = FE.get_feature_maps(mito_patch)\n",
    "test_mu_mito = np.expand_dims(test_mu_mito, axis=0)\n",
    "\n",
    "p.plot_w_b( (test_slice, \"Test Image\", (y, x, patch_size)),\\\n",
    "        (test_slice_lbl, \"Ground truth label\", (y, x, patch_size)),\\\n",
    "        (mito_patch, \"Random patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (mito_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l'],\n",
    "        box_size=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_3d = TSNE(\n",
    "    n_components=3,\n",
    "    random_state=42,\n",
    "    learning_rate=\"auto\",\n",
    "    metric=\"euclidean\",\n",
    "    n_iter=10000,\n",
    ").fit(train_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "        (0.8, 0.8, 0.8),               # white for label -1\n",
    "        (1, 0.8, 0.9),          # pink for label 0\n",
    "        (230/255, 159/255, 0),  # orange for label 1\n",
    "        (0.5803921568627451, 0.403921568627451, 0.7411764705882353), # violet for label 2\n",
    "        (0, 158/255, 115/255),  # bluish green for label 3\n",
    "        \n",
    "    ]\n",
    "\n",
    "# Create the colormap\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "# Define the bounds and normalization\n",
    "bounds = [-1, 0, 1, 2, 3, 4]    \n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "label = ['Background', 'Nucleus', 'Granule', 'Mito']\n",
    "# Plot the data points with true labels\n",
    "for i in range(4):\n",
    "    cluster_points = tsne_3d[train_labels == i]\n",
    "    ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], label=label[i], c=sample_size*[i], cmap=cmap, norm=norm)\n",
    "\n",
    "ax.set_title(\"3D t-SNE Visualization of High-Dimensional Data\")\n",
    "ax.set_xlabel(\"t-SNE Component 1\")\n",
    "ax.set_ylabel(\"t-SNE Component 2\")\n",
    "ax.set_zlabel(\"t-SNE Component 3\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = []\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    learning_rate=\"auto\",\n",
    "    metric=\"cosine\",\n",
    "    n_iter=10000,\n",
    ").fit(train_mu)\n",
    "bg_tsne = tsne[:sample_size]\n",
    "nuc_tsne = tsne[sample_size:2*sample_size]\n",
    "gra_tsne = tsne[2*sample_size:3*sample_size]\n",
    "mito_tsne = tsne[3*sample_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tsne = tsne.transform(test_mu_bg)\n",
    "point_size = 5\n",
    "p.plot_w_b( (bg_patch, \"Test patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (bg_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"TSNE - one test sample\",\\\n",
    "                 [([0]*sample_size,point_size), ([1]*sample_size,point_size), ([2]*sample_size,point_size),\\\n",
    "                   ([3]*sample_size,point_size), ([0],point_size)]),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'scatter'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tsne = tsne.transform(test_mu_nuc)\n",
    "point_size = 5\n",
    "p.plot_w_b( (nuc_patch, \"Test patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (nuc_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"TSNE - one test sample\",\\\n",
    "                 [([0]*sample_size,point_size), ([1]*sample_size,point_size), ([2]*sample_size,point_size),\\\n",
    "                   ([3]*sample_size,point_size), ([1],point_size)]),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'scatter'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tsne = tsne.transform(test_mu_gra)\n",
    "point_size = 5\n",
    "p.plot_w_b( (gra_patch, \"Test patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (gra_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"TSNE - one test sample\",\\\n",
    "                 [([0]*sample_size,point_size), ([1]*sample_size,point_size), ([2]*sample_size,point_size),\\\n",
    "                   ([3]*sample_size,point_size), ([2],point_size)]),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'scatter'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tsne = tsne.transform(test_mu_mito)\n",
    "point_size = 5\n",
    "p.plot_w_b( (mito_patch, \"Test patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (mito_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"TSNE - one test sample\",\\\n",
    "                 [([0]*sample_size,point_size), ([1]*sample_size,point_size), ([2]*sample_size,point_size),\\\n",
    "                   ([3]*sample_size,point_size), ([3],point_size)]),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'scatter'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(tsne)\n",
    "train_labels_kmean = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(train_labels_kmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_kmean\n",
    "test_kmeans = kmeans.predict(test_tsne)\n",
    "point_size = 5\n",
    "p.plot_w_b( (mito_patch, \"Test patch\", (pad_size, pad_size, centre_size)),\\\n",
    "        (mito_label, \"Ground truth label\", (pad_size, pad_size, centre_size)),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"TSNE - one test sample\",\\\n",
    "                 [([0]*sample_size,point_size), ([1]*sample_size,point_size), ([2]*sample_size,point_size),\\\n",
    "                   ([3]*sample_size,point_size), ([3],point_size)]),\\\n",
    "        ([bg_tsne, nuc_tsne, gra_tsne, mito_tsne, test_tsne], \"KMeans - one test sample\",\\\n",
    "                 [(train_labels_kmean[:sample_size],point_size), (train_labels_kmean[sample_size:2*sample_size],point_size),\\\n",
    "                  (train_labels_kmean[2*sample_size:3*sample_size],point_size),(train_labels_kmean[3*sample_size:],point_size), (test_kmeans,point_size)]),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'scatter', 'scatter'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "x_mu_reduced = pca.fit_transform(train_mu)\n",
    "# new_point_reduced = pca.transform(feature_map.reshape(1, -1))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mus_normalized = scaler.fit_transform(x_mu_reduced)\n",
    "\n",
    "gmm = GaussianMixture(n_components=4, covariance_type='tied', random_state=0)\n",
    "gmm.fit(mus_normalized)\n",
    "# new_mu_normalized = scaler.transform(new_point_reduced.reshape(1, -1))\n",
    "\n",
    "# probs = gmm.predict_proba(new_mu_normalized)\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gmm = gmm.predict(mus_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(labels_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Agglomerative clustering\n",
    "agg_ari = adjusted_rand_score(true_labels, agg_labels)\n",
    "agg_nmi = normalized_mutual_info_score(true_labels, agg_labels)\n",
    "\n",
    "print(\"Agglomerative Clustering ARI:\", agg_ari)\n",
    "print(\"Agglomerative Clustering NMI:\", agg_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 575\n",
    "x2 = 725\n",
    "y1 = 175\n",
    "y2 = 325\n",
    "p.plot_w_b((test_slice[y1:y2, x1:x2], \"Test image\", False),\\\n",
    "            (test_slice_lbl[y1:y2, x1:x2], \"GT label\", False),\\\n",
    "            plot_types=['imshow', 'imshow_l'],\n",
    "            box_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "H, W = test_slice.shape\n",
    "pred = np.zeros((H, W))\n",
    "latent_embedding = np.zeros((H, W, 43008))\n",
    "for i in range(0, H-patch_size, 1):\n",
    "    for j in range(0, W-patch_size, 1):\n",
    "        pred[i+30:i+34,j+30:j+34] += 1\n",
    "        latent_embedding[i+30:i+34,j+30:j+34,:] += (FE.get_feature_maps(torch.from_numpy(test_slice[i:i+patch_size, j:j+patch_size])))/16\n",
    "coords = np.column_stack(np.where(pred == 16))\n",
    "min_row, min_col = coords.min(axis=0)\n",
    "max_row, max_col = coords.max(axis=0)\n",
    "label_pred = np.zeros((max_row-min_row+1, max_col-min_col+1))\n",
    "for i in range(min_row, max_row+1):\n",
    "    for j in range(min_col, max_col+1):\n",
    "        label_pred[i-min_row, j-min_col] = FE.get_closest(train_mu, latent_embedding[i, j])\n",
    "cropped_image = pred[min_row:max_row+1, min_col:max_col+1]\n",
    "plt.imshow(label_pred)\n",
    "print(min_row, max_row, min_col, max_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = test_images[i][y1:y2, x1:x2].shape\n",
    "new_h, new_w = h - patch_size + 1, w - patch_size + 1\n",
    "feature_maps = np.zeros((new_h, new_w))\n",
    "all_patches, all_labels = dp.get_all_patches(test_slice[y1:y2, x1:x2], test_slice_lbl[y1:y2, x1:x2], patch_size, stride=1)\n",
    "idx = 0\n",
    "for y in tqdm(range(new_h)):\n",
    "    for x in range(new_w):\n",
    "        mu = FE.get_feature_maps(all_patches[idx])\n",
    "        feature_maps[y][x] = FE.get_closest(train_mu, mu)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = np.where(test_slice_lbl[y1+pad_size:y2-pad_size-3, x1+pad_size:x2-pad_size-3] != -1, feature_maps, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot_w_b( (test_slice[y1:y2, x1:x2], \"Input\", (pad_size, pad_size, 87)),\\\n",
    "        (test_slice_lbl[y1:y2, x1:x2], \"GT label\", (pad_size, pad_size, 87)),\\\n",
    "        (test_slice[y1+pad_size:y2-pad_size-3, x1+pad_size:x2-pad_size-3], \"Input cropped\", False),\\\n",
    "        (test_slice_lbl[y1+pad_size:y2-pad_size-3, x1+pad_size:x2-pad_size-3], \"GT label cropped\", False),\\\n",
    "        (feature_maps, \"Prediction\", False),\\\n",
    "        plot_types=['imshow', 'imshow_l', 'imshow', 'imshow_l', 'imshow_l'],\n",
    "        box_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(feature_maps, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
