{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Hierarchical DivNoising network for Convallaria data which is intrinsically noisy\n",
    "This notebook contains an example on how to train a Hierarchical DivNoising Ladder VAE for an intrinsically noisy data. This requires having a noise model (model of the imaging noise) which can be either measured from calibration data or bootstrapped from raw noisy images themselves. If you haven't done so, please first run '1-CreateNoiseModel.ipynb', which will download the data and create a noise model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We import all our dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from models.lvae import LadderVAE\n",
    "from lib.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "import training\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify ```path``` to load training data\n",
    "Your data should be stored in the directory indicated by ```path```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"/group/jug/Sheida/maester_data/download/high_c1/\"\n",
    "observation= imread(path+'high_c1_source.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we need to follow some preprocessing steps first which will prepare the data for training purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first divide the data into training and validation sets with 85% images allocated to training set  and rest to validation set. Then we augment the training data 8-fold by 90 degree rotations and flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (932, 699, 760) Shape of validation images: (165, 699, 760)\n"
     ]
    }
   ],
   "source": [
    "train_data = observation[:int(0.85*observation.shape[0])]\n",
    "val_data= observation[int(0.85*observation.shape[0]):]\n",
    "print(\"Shape of training images:\", train_data.shape, \"Shape of validation images:\", val_data.shape)\n",
    "# train_data = utils.augment_data(train_data) ### Data augmentation disabled for fast training, but can be enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### We extract overlapping patches of size ```patch_size x patch_size``` from training and validation images.\n",
    "### Usually 64x64 patches work well for most microscopy datasets\n",
    "patch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 932/932 [00:00<00:00, 1150.00it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 1150.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (5000, 128, 128) Shape of validation images: (500, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_width = observation.shape[2]\n",
    "img_height = observation.shape[1]\n",
    "num_patches = int(float(img_width*img_height)/float(patch_size**2)*1)\n",
    "train_images = utils.extract_patches(train_data, patch_size, num_patches)\n",
    "train_images = train_images[:5000]\n",
    "val_images = utils.extract_patches(val_data, patch_size, num_patches)\n",
    "val_images = val_images[:500] # We limit validation patches to 1000 to speed up training but it is not necessary\n",
    "test_images = val_images[:100]\n",
    "img_shape = (train_images.shape[1], train_images.shape[2])\n",
    "print(\"Shape of training images:\", train_images.shape, \"Shape of validation images:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Hierarchical DivNoising model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>model_name</code> specifies the name of the model with which the weights will be saved and wil be loaded later for prediction.<br>\n",
    "<code>directory_path</code> specifies the directory where the model weights and the intermediate denoising and generation results will be saved. <br>\n",
    "<code>gaussian_noise_std</code> is only applicable if dataset is synthetically corrupted with Gaussian noise of known std. For real datasets, it should be set to ```None```.<br>\n",
    "<code>noiseModel</code> specifies a noise model for training. If noisy data is generated synthetically using Gaussian noise, set it to None. Else set it to the GMM based noise model (.npz file)  generated from '1-CreateNoiseModel.ipynb'.<br>\n",
    "<code>batch_size</code> specifies the batch size used for training. The default batch size of $64$ works well for most microscopy datasets.<br>\n",
    "<code>virtual_batch</code> specifies the virtual batch size used for training. It divides the <code>batch_size</code> into smaller mini-batches of size <code>virtual_batch</code>. Decrease this if batches do not fit in memory.<br>\n",
    "<code>test_batch_size</code> specifies the batch size used for testing every $1000$ training steps. Decrease this if test batches do not fit in memory, it does not have any consequence on training. It is just for intermediate visual debugging.<br>\n",
    "<code>lr</code> specifies the learning rate.<br>\n",
    "<code>max_epochs</code> specifies the total number of training epochs. Around $150-200$ epochs work well generally.<br>\n",
    "<code>steps_per_epoch</code> specifies how many steps to take per epoch of training. Around $400-500$ steps work well for most datasets.<br>\n",
    "<code>num_latents</code> specifies the number of stochastic layers. The default setting of $6$ works well for most datasets but quite good results can also be obtained with as less as $4$ layers. However, more stochastic layers may improve performance for some datasets at the cost of increased training time.<br>\n",
    "<code>z_dims</code> specifies the number of bottleneck dimensions (latent space dimensions) at each stochastic layer per pixel. The default setting of $32$ works well for most datasets.<br>\n",
    "<code>blocks_per_layer</code> specifies how many residual blocks to use per stochastic layer. Usually, setting it to be $4$ or more works well. However, more residual blocks improve performance at the cost of increased training time.<br>\n",
    "<code>batchnorm</code> specifies if batch normalization is used or not. Turning it to True is recommended.<br>\n",
    "<code>free_bits</code> specifies the threshold below which KL loss is not optimized for. This prevents the [KL-collapse problem](https://arxiv.org/pdf/1511.06349.pdf%3Futm_campaign%3DRevue%2520newsletter%26utm_medium%3DNewsletter%26utm_source%3Drevue). The default setting of $1.0$ works well for most datasets.<br>\n",
    "\n",
    "**__Note:__** With these settings, training will take approximately $24$ hours on Tesla P100/Titan Xp GPU needing about 6 GB GPU memory. We optimized the code to run on less GPU memory. For faster training, consider increasing ```virtual_batch_size``` but since we have not tested with different settings of ```virtual_batch_size```, we do not yet know how this affects results. To reduce traing time, also consider reducing either ```num_latents``` or ```blocks_per_layer``` to $4$. These settings will bring down the training time to around $12-15$ hours while still giving good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"HDN Muller\"\n",
    "directory_path = \"./Trained_model/\" \n",
    "\n",
    "# Data-specific\n",
    "gaussian_noise_std = None\n",
    "# noise_model_params= np.load(\"./data/Convallaria_diaphragm/GMMNoiseModel_convallaria_3_2_calibration.npz\")\n",
    "noiseModel = None #GaussianMixtureNoiseModel(params = noise_model_params, device = device)\n",
    "\n",
    "# Training-specific\n",
    "batch_size=32\n",
    "virtual_batch = 16\n",
    "lr=3e-4\n",
    "max_epochs = 500\n",
    "steps_per_epoch=400\n",
    "test_batch_size=100\n",
    "\n",
    "# Model-specific\n",
    "num_latents = 5\n",
    "z_dims = [32]*int(num_latents)\n",
    "blocks_per_layer = 5\n",
    "batchnorm = True\n",
    "free_bits = 0.0 # if KLD is less than 1 then the loss won't be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug             = False #[True, False]\n",
    "save_output       = True #[True, False]\n",
    "project           = 'HDN_Muller'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LadderVAE(\n",
       "  (first_bottom_up): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): BottomUpDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (top_down_layers): ModuleList(\n",
       "    (0-3): 4 x TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_p): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (merge): MergeLayer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (skip_connection_merger): SkipConnectionMerger(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottom_up_layers): ModuleList(\n",
       "    (0-4): 5 x BottomUpLayer(\n",
       "      (net): Sequential(\n",
       "        (0): BottomUpDeterministicResBlock(\n",
       "          (pre_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_top_down): Sequential(\n",
       "    (0): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (parameter_net): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, data_mean, data_std = boilerplate._make_datamanager(train_images,val_images,\n",
    "                                                                                           test_images,batch_size,\n",
    "                                                                                           test_batch_size)\n",
    "\n",
    "model = LadderVAE(z_dims=z_dims,blocks_per_layer=blocks_per_layer,data_mean=data_mean,data_std=data_std,noiseModel=noiseModel,\n",
    "                  device=device,batchnorm=batchnorm,free_bits=free_bits,img_shape=img_shape).cuda()\n",
    "\n",
    "model.train() # Model set in training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msheida-rk\u001b[0m (\u001b[33mjuglab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sheida.rahnamai/GIT/HDN/examples/Pixel_Noise/Convallaria/wandb/run-20231205_003838-6k3uewir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juglab/HDN_Muller/runs/6k3uewir' target=\"_blank\">super-rain-8</a></strong> to <a href='https://wandb.ai/juglab/HDN_Muller' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juglab/HDN_Muller' target=\"_blank\">https://wandb.ai/juglab/HDN_Muller</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juglab/HDN_Muller/runs/6k3uewir' target=\"_blank\">https://wandb.ai/juglab/HDN_Muller/runs/6k3uewir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/500] Training Loss: 1.031 Reconstruction Loss: 0.537 KL Loss: 0.494\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.47221386432647705 Min validation loss: 0.47221386432647705\n",
      "Time for epoch: 5seconds\n",
      "Est remaining time: 0:41:35 or 2495 seconds\n",
      "----------------------------------------\n",
      "Epoch[2/500] Training Loss: 0.952 Reconstruction Loss: 0.557 KL Loss: 0.394\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.463153600692749 Min validation loss: 0.463153600692749\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:54 or 1494 seconds\n",
      "----------------------------------------\n",
      "Epoch[3/500] Training Loss: 0.878 Reconstruction Loss: 0.528 KL Loss: 0.350\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.4590204954147339 Min validation loss: 0.4590204954147339\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:51 or 1491 seconds\n",
      "----------------------------------------\n",
      "Epoch[4/500] Training Loss: 0.846 Reconstruction Loss: 0.524 KL Loss: 0.322\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.45552295446395874 Min validation loss: 0.45552295446395874\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:48 or 1488 seconds\n",
      "----------------------------------------\n",
      "Epoch[5/500] Training Loss: 0.782 Reconstruction Loss: 0.475 KL Loss: 0.307\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.450225830078125 Min validation loss: 0.450225830078125\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:45 or 1485 seconds\n",
      "----------------------------------------\n",
      "Epoch[6/500] Training Loss: 0.696 Reconstruction Loss: 0.396 KL Loss: 0.300\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.4365847110748291 Min validation loss: 0.4365847110748291\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:32:56 or 1976 seconds\n",
      "----------------------------------------\n",
      "Epoch[7/500] Training Loss: 0.642 Reconstruction Loss: 0.330 KL Loss: 0.311\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.4103424549102783 Min validation loss: 0.4103424549102783\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:32:52 or 1972 seconds\n",
      "----------------------------------------\n",
      "Epoch[8/500] Training Loss: 0.638 Reconstruction Loss: 0.327 KL Loss: 0.311\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3948094844818115 Min validation loss: 0.3948094844818115\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:36 or 1476 seconds\n",
      "----------------------------------------\n",
      "Epoch[9/500] Training Loss: 0.608 Reconstruction Loss: 0.312 KL Loss: 0.297\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.393213152885437 Min validation loss: 0.393213152885437\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:33 or 1473 seconds\n",
      "----------------------------------------\n",
      "Epoch[10/500] Training Loss: 0.599 Reconstruction Loss: 0.324 KL Loss: 0.275\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.39168867468833923 Min validation loss: 0.39168867468833923\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:30 or 1470 seconds\n",
      "----------------------------------------\n",
      "Epoch[11/500] Training Loss: 0.574 Reconstruction Loss: 0.317 KL Loss: 0.257\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3881256580352783 Min validation loss: 0.3881256580352783\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:27 or 1467 seconds\n",
      "----------------------------------------\n",
      "Epoch[12/500] Training Loss: 0.571 Reconstruction Loss: 0.326 KL Loss: 0.245\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3784859776496887 Min validation loss: 0.3784859776496887\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:24 or 1464 seconds\n",
      "----------------------------------------\n",
      "Epoch[13/500] Training Loss: 0.584 Reconstruction Loss: 0.343 KL Loss: 0.240\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.35970473289489746 Min validation loss: 0.35970473289489746\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:32:28 or 1948 seconds\n",
      "----------------------------------------\n",
      "Epoch[14/500] Training Loss: 0.544 Reconstruction Loss: 0.308 KL Loss: 0.236\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3371122479438782 Min validation loss: 0.3371122479438782\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:32:24 or 1944 seconds\n",
      "----------------------------------------\n",
      "Epoch[15/500] Training Loss: 0.517 Reconstruction Loss: 0.285 KL Loss: 0.232\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3229219317436218 Min validation loss: 0.3229219317436218\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:15 or 1455 seconds\n",
      "----------------------------------------\n",
      "Epoch[16/500] Training Loss: 0.527 Reconstruction Loss: 0.294 KL Loss: 0.233\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.32020139694213867 Min validation loss: 0.32020139694213867\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:12 or 1452 seconds\n",
      "----------------------------------------\n",
      "Epoch[17/500] Training Loss: 0.515 Reconstruction Loss: 0.287 KL Loss: 0.228\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.3175962567329407 Min validation loss: 0.3175962567329407\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:09 or 1449 seconds\n",
      "----------------------------------------\n",
      "Epoch[18/500] Training Loss: 0.519 Reconstruction Loss: 0.296 KL Loss: 0.223\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.31124091148376465 Min validation loss: 0.31124091148376465\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:32:08 or 1928 seconds\n",
      "----------------------------------------\n",
      "Epoch[19/500] Training Loss: 0.494 Reconstruction Loss: 0.279 KL Loss: 0.215\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.30485665798187256 Min validation loss: 0.30485665798187256\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:03 or 1443 seconds\n",
      "----------------------------------------\n",
      "Epoch[20/500] Training Loss: 0.483 Reconstruction Loss: 0.277 KL Loss: 0.206\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.300571084022522 Min validation loss: 0.300571084022522\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:24:00 or 1440 seconds\n",
      "----------------------------------------\n",
      "Epoch[21/500] Training Loss: 0.505 Reconstruction Loss: 0.301 KL Loss: 0.204\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.298706591129303 Min validation loss: 0.298706591129303\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:31:56 or 1916 seconds\n",
      "----------------------------------------\n",
      "Epoch[22/500] Training Loss: 0.479 Reconstruction Loss: 0.284 KL Loss: 0.195\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.29798948764801025 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:54 or 1434 seconds\n",
      "----------------------------------------\n",
      "Epoch[23/500] Training Loss: 0.479 Reconstruction Loss: 0.288 KL Loss: 0.191\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.2985047698020935 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:51 or 1431 seconds\n",
      "----------------------------------------\n",
      "Epoch[24/500] Training Loss: 0.463 Reconstruction Loss: 0.275 KL Loss: 0.188\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.29980286955833435 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:48 or 1428 seconds\n",
      "----------------------------------------\n",
      "Epoch[25/500] Training Loss: 0.455 Reconstruction Loss: 0.271 KL Loss: 0.184\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 3 Validation Loss: 0.30512535572052 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:45 or 1425 seconds\n",
      "----------------------------------------\n",
      "Epoch[26/500] Training Loss: 0.455 Reconstruction Loss: 0.274 KL Loss: 0.181\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 4 Validation Loss: 0.31373828649520874 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:42 or 1422 seconds\n",
      "----------------------------------------\n",
      "Epoch[27/500] Training Loss: 0.466 Reconstruction Loss: 0.281 KL Loss: 0.185\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 5 Validation Loss: 0.32463860511779785 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:39 or 1419 seconds\n",
      "----------------------------------------\n",
      "Epoch[28/500] Training Loss: 0.442 Reconstruction Loss: 0.262 KL Loss: 0.180\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 6 Validation Loss: 0.32739752531051636 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:36 or 1416 seconds\n",
      "----------------------------------------\n",
      "Epoch[29/500] Training Loss: 0.439 Reconstruction Loss: 0.261 KL Loss: 0.178\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 7 Validation Loss: 0.324260950088501 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:33 or 1413 seconds\n",
      "----------------------------------------\n",
      "Epoch[30/500] Training Loss: 0.435 Reconstruction Loss: 0.260 KL Loss: 0.175\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 8 Validation Loss: 0.31496286392211914 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:30 or 1410 seconds\n",
      "----------------------------------------\n",
      "Epoch[31/500] Training Loss: 0.446 Reconstruction Loss: 0.274 KL Loss: 0.172\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 9 Validation Loss: 0.3080191910266876 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:27 or 1407 seconds\n",
      "----------------------------------------\n",
      "Epoch[32/500] Training Loss: 0.438 Reconstruction Loss: 0.273 KL Loss: 0.165\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 10 Validation Loss: 0.302921861410141 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:24 or 1404 seconds\n",
      "----------------------------------------\n",
      "Epoch[33/500] Training Loss: 0.431 Reconstruction Loss: 0.272 KL Loss: 0.158\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00033: reducing learning rate of group 0 to 1.5000e-04.\n",
      "Patience: 11 Validation Loss: 0.29954850673675537 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:21 or 1401 seconds\n",
      "----------------------------------------\n",
      "Epoch[34/500] Training Loss: 0.435 Reconstruction Loss: 0.277 KL Loss: 0.157\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 12 Validation Loss: 0.30020907521247864 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:18 or 1398 seconds\n",
      "----------------------------------------\n",
      "Epoch[35/500] Training Loss: 0.428 Reconstruction Loss: 0.276 KL Loss: 0.152\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 13 Validation Loss: 0.3022971749305725 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:15 or 1395 seconds\n",
      "----------------------------------------\n",
      "Epoch[36/500] Training Loss: 0.423 Reconstruction Loss: 0.273 KL Loss: 0.150\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 14 Validation Loss: 0.30358949303627014 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:12 or 1392 seconds\n",
      "----------------------------------------\n",
      "Epoch[37/500] Training Loss: 0.429 Reconstruction Loss: 0.276 KL Loss: 0.153\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 15 Validation Loss: 0.30410295724868774 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:09 or 1389 seconds\n",
      "----------------------------------------\n",
      "Epoch[38/500] Training Loss: 0.429 Reconstruction Loss: 0.277 KL Loss: 0.151\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 16 Validation Loss: 0.30695781111717224 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:06 or 1386 seconds\n",
      "----------------------------------------\n",
      "Epoch[39/500] Training Loss: 0.415 Reconstruction Loss: 0.265 KL Loss: 0.151\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 17 Validation Loss: 0.30613428354263306 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:03 or 1383 seconds\n",
      "----------------------------------------\n",
      "Epoch[40/500] Training Loss: 0.424 Reconstruction Loss: 0.273 KL Loss: 0.151\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 18 Validation Loss: 0.3059397339820862 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:23:00 or 1380 seconds\n",
      "----------------------------------------\n",
      "Epoch[41/500] Training Loss: 0.424 Reconstruction Loss: 0.271 KL Loss: 0.152\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 19 Validation Loss: 0.30518534779548645 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:57 or 1377 seconds\n",
      "----------------------------------------\n",
      "Epoch[42/500] Training Loss: 0.408 Reconstruction Loss: 0.258 KL Loss: 0.150\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 20 Validation Loss: 0.3062189519405365 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:54 or 1374 seconds\n",
      "----------------------------------------\n",
      "Epoch[43/500] Training Loss: 0.420 Reconstruction Loss: 0.271 KL Loss: 0.149\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 21 Validation Loss: 0.3035877048969269 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:30:28 or 1828 seconds\n",
      "----------------------------------------\n",
      "Epoch[44/500] Training Loss: 0.408 Reconstruction Loss: 0.260 KL Loss: 0.148\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00044: reducing learning rate of group 0 to 7.5000e-05.\n",
      "Patience: 22 Validation Loss: 0.29949408769607544 Min validation loss: 0.29798948764801025\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:48 or 1368 seconds\n",
      "----------------------------------------\n",
      "Epoch[45/500] Training Loss: 0.419 Reconstruction Loss: 0.271 KL Loss: 0.149\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.29719972610473633 Min validation loss: 0.29719972610473633\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:45 or 1365 seconds\n",
      "----------------------------------------\n",
      "Epoch[46/500] Training Loss: 0.409 Reconstruction Loss: 0.266 KL Loss: 0.143\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2957698106765747 Min validation loss: 0.2957698106765747\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:42 or 1362 seconds\n",
      "----------------------------------------\n",
      "Epoch[47/500] Training Loss: 0.417 Reconstruction Loss: 0.270 KL Loss: 0.147\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2943575084209442 Min validation loss: 0.2943575084209442\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:39 or 1359 seconds\n",
      "----------------------------------------\n",
      "Epoch[48/500] Training Loss: 0.407 Reconstruction Loss: 0.262 KL Loss: 0.145\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2941820025444031 Min validation loss: 0.2941820025444031\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:36 or 1356 seconds\n",
      "----------------------------------------\n",
      "Epoch[49/500] Training Loss: 0.398 Reconstruction Loss: 0.256 KL Loss: 0.142\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2933129668235779 Min validation loss: 0.2933129668235779\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:33 or 1353 seconds\n",
      "----------------------------------------\n",
      "Epoch[50/500] Training Loss: 0.413 Reconstruction Loss: 0.270 KL Loss: 0.143\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.291360080242157 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:30 or 1350 seconds\n",
      "----------------------------------------\n",
      "Epoch[51/500] Training Loss: 0.415 Reconstruction Loss: 0.271 KL Loss: 0.145\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.29251378774642944 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:27 or 1347 seconds\n",
      "----------------------------------------\n",
      "Epoch[52/500] Training Loss: 0.412 Reconstruction Loss: 0.272 KL Loss: 0.140\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.2923162579536438 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:24 or 1344 seconds\n",
      "----------------------------------------\n",
      "Epoch[53/500] Training Loss: 0.411 Reconstruction Loss: 0.271 KL Loss: 0.140\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 3 Validation Loss: 0.2925167679786682 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:21 or 1341 seconds\n",
      "----------------------------------------\n",
      "Epoch[54/500] Training Loss: 0.420 Reconstruction Loss: 0.278 KL Loss: 0.141\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 4 Validation Loss: 0.29268622398376465 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:18 or 1338 seconds\n",
      "----------------------------------------\n",
      "Epoch[55/500] Training Loss: 0.404 Reconstruction Loss: 0.265 KL Loss: 0.138\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 5 Validation Loss: 0.2940940856933594 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:15 or 1335 seconds\n",
      "----------------------------------------\n",
      "Epoch[56/500] Training Loss: 0.405 Reconstruction Loss: 0.264 KL Loss: 0.141\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 6 Validation Loss: 0.2947293519973755 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:12 or 1332 seconds\n",
      "----------------------------------------\n",
      "Epoch[57/500] Training Loss: 0.398 Reconstruction Loss: 0.261 KL Loss: 0.137\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 7 Validation Loss: 0.2944421172142029 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:09 or 1329 seconds\n",
      "----------------------------------------\n",
      "Epoch[58/500] Training Loss: 0.412 Reconstruction Loss: 0.272 KL Loss: 0.139\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 8 Validation Loss: 0.2947466969490051 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:06 or 1326 seconds\n",
      "----------------------------------------\n",
      "Epoch[59/500] Training Loss: 0.410 Reconstruction Loss: 0.271 KL Loss: 0.139\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 9 Validation Loss: 0.29484057426452637 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:03 or 1323 seconds\n",
      "----------------------------------------\n",
      "Epoch[60/500] Training Loss: 0.395 Reconstruction Loss: 0.260 KL Loss: 0.135\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 10 Validation Loss: 0.2943599224090576 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:22:00 or 1320 seconds\n",
      "----------------------------------------\n",
      "Epoch[61/500] Training Loss: 0.385 Reconstruction Loss: 0.252 KL Loss: 0.133\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00061: reducing learning rate of group 0 to 3.7500e-05.\n",
      "Patience: 11 Validation Loss: 0.29545655846595764 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:57 or 1317 seconds\n",
      "----------------------------------------\n",
      "Epoch[62/500] Training Loss: 0.396 Reconstruction Loss: 0.259 KL Loss: 0.137\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 12 Validation Loss: 0.2955241799354553 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:54 or 1314 seconds\n",
      "----------------------------------------\n",
      "Epoch[63/500] Training Loss: 0.402 Reconstruction Loss: 0.264 KL Loss: 0.138\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 13 Validation Loss: 0.2938959002494812 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:51 or 1311 seconds\n",
      "----------------------------------------\n",
      "Epoch[64/500] Training Loss: 0.399 Reconstruction Loss: 0.262 KL Loss: 0.137\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 14 Validation Loss: 0.29406553506851196 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:48 or 1308 seconds\n",
      "----------------------------------------\n",
      "Epoch[65/500] Training Loss: 0.395 Reconstruction Loss: 0.261 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 15 Validation Loss: 0.29371005296707153 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:45 or 1305 seconds\n",
      "----------------------------------------\n",
      "Epoch[66/500] Training Loss: 0.400 Reconstruction Loss: 0.264 KL Loss: 0.135\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 16 Validation Loss: 0.29297125339508057 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:42 or 1302 seconds\n",
      "----------------------------------------\n",
      "Epoch[67/500] Training Loss: 0.392 Reconstruction Loss: 0.258 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 17 Validation Loss: 0.29182812571525574 Min validation loss: 0.291360080242157\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:39 or 1299 seconds\n",
      "----------------------------------------\n",
      "Epoch[68/500] Training Loss: 0.407 Reconstruction Loss: 0.271 KL Loss: 0.136\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2908405661582947 Min validation loss: 0.2908405661582947\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:36 or 1296 seconds\n",
      "----------------------------------------\n",
      "Epoch[69/500] Training Loss: 0.389 Reconstruction Loss: 0.254 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2899438738822937 Min validation loss: 0.2899438738822937\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:33 or 1293 seconds\n",
      "----------------------------------------\n",
      "Epoch[70/500] Training Loss: 0.401 Reconstruction Loss: 0.267 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28987476229667664 Min validation loss: 0.28987476229667664\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:30 or 1290 seconds\n",
      "----------------------------------------\n",
      "Epoch[71/500] Training Loss: 0.399 Reconstruction Loss: 0.265 KL Loss: 0.133\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2888328433036804 Min validation loss: 0.2888328433036804\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:27 or 1287 seconds\n",
      "----------------------------------------\n",
      "Epoch[72/500] Training Loss: 0.399 Reconstruction Loss: 0.265 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28823620080947876 Min validation loss: 0.28823620080947876\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:28:32 or 1712 seconds\n",
      "----------------------------------------\n",
      "Epoch[73/500] Training Loss: 0.391 Reconstruction Loss: 0.260 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2876984477043152 Min validation loss: 0.2876984477043152\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:21 or 1281 seconds\n",
      "----------------------------------------\n",
      "Epoch[74/500] Training Loss: 0.390 Reconstruction Loss: 0.259 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28756392002105713 Min validation loss: 0.28756392002105713\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:28:24 or 1704 seconds\n",
      "----------------------------------------\n",
      "Epoch[75/500] Training Loss: 0.392 Reconstruction Loss: 0.258 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28642454743385315 Min validation loss: 0.28642454743385315\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:15 or 1275 seconds\n",
      "----------------------------------------\n",
      "Epoch[76/500] Training Loss: 0.407 Reconstruction Loss: 0.273 KL Loss: 0.134\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2854296565055847 Min validation loss: 0.2854296565055847\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:28:16 or 1696 seconds\n",
      "----------------------------------------\n",
      "Epoch[77/500] Training Loss: 0.389 Reconstruction Loss: 0.258 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.28580451011657715 Min validation loss: 0.2854296565055847\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:09 or 1269 seconds\n",
      "----------------------------------------\n",
      "Epoch[78/500] Training Loss: 0.395 Reconstruction Loss: 0.262 KL Loss: 0.132\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28530633449554443 Min validation loss: 0.28530633449554443\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:28:08 or 1688 seconds\n",
      "----------------------------------------\n",
      "Epoch[79/500] Training Loss: 0.402 Reconstruction Loss: 0.270 KL Loss: 0.132\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.28580236434936523 Min validation loss: 0.28530633449554443\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:03 or 1263 seconds\n",
      "----------------------------------------\n",
      "Epoch[80/500] Training Loss: 0.397 Reconstruction Loss: 0.267 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.28695082664489746 Min validation loss: 0.28530633449554443\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:21:00 or 1260 seconds\n",
      "----------------------------------------\n",
      "Epoch[81/500] Training Loss: 0.383 Reconstruction Loss: 0.252 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 3 Validation Loss: 0.2866719961166382 Min validation loss: 0.28530633449554443\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:57 or 1257 seconds\n",
      "----------------------------------------\n",
      "Epoch[82/500] Training Loss: 0.388 Reconstruction Loss: 0.257 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 4 Validation Loss: 0.28591740131378174 Min validation loss: 0.28530633449554443\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:54 or 1254 seconds\n",
      "----------------------------------------\n",
      "Epoch[83/500] Training Loss: 0.397 Reconstruction Loss: 0.266 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2846643626689911 Min validation loss: 0.2846643626689911\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:27:48 or 1668 seconds\n",
      "----------------------------------------\n",
      "Epoch[84/500] Training Loss: 0.395 Reconstruction Loss: 0.262 KL Loss: 0.133\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.284706175327301 Min validation loss: 0.2846643626689911\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:48 or 1248 seconds\n",
      "----------------------------------------\n",
      "Epoch[85/500] Training Loss: 0.389 Reconstruction Loss: 0.260 KL Loss: 0.129\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28455936908721924 Min validation loss: 0.28455936908721924\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:45 or 1245 seconds\n",
      "----------------------------------------\n",
      "Epoch[86/500] Training Loss: 0.395 Reconstruction Loss: 0.265 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2842300832271576 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:27:36 or 1656 seconds\n",
      "----------------------------------------\n",
      "Epoch[87/500] Training Loss: 0.394 Reconstruction Loss: 0.262 KL Loss: 0.131\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.28432875871658325 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:39 or 1239 seconds\n",
      "----------------------------------------\n",
      "Epoch[88/500] Training Loss: 0.390 Reconstruction Loss: 0.260 KL Loss: 0.129\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.2852606177330017 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:36 or 1236 seconds\n",
      "----------------------------------------\n",
      "Epoch[89/500] Training Loss: 0.402 Reconstruction Loss: 0.272 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 3 Validation Loss: 0.2848416566848755 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:33 or 1233 seconds\n",
      "----------------------------------------\n",
      "Epoch[90/500] Training Loss: 0.399 Reconstruction Loss: 0.269 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 4 Validation Loss: 0.2846214771270752 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:30 or 1230 seconds\n",
      "----------------------------------------\n",
      "Epoch[91/500] Training Loss: 0.393 Reconstruction Loss: 0.264 KL Loss: 0.129\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 5 Validation Loss: 0.28505462408065796 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:27 or 1227 seconds\n",
      "----------------------------------------\n",
      "Epoch[92/500] Training Loss: 0.399 Reconstruction Loss: 0.269 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 6 Validation Loss: 0.28532499074935913 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:24 or 1224 seconds\n",
      "----------------------------------------\n",
      "Epoch[93/500] Training Loss: 0.392 Reconstruction Loss: 0.264 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 7 Validation Loss: 0.28586864471435547 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:21 or 1221 seconds\n",
      "----------------------------------------\n",
      "Epoch[94/500] Training Loss: 0.388 Reconstruction Loss: 0.260 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 8 Validation Loss: 0.2873702049255371 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:18 or 1218 seconds\n",
      "----------------------------------------\n",
      "Epoch[95/500] Training Loss: 0.391 Reconstruction Loss: 0.262 KL Loss: 0.129\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 9 Validation Loss: 0.28914690017700195 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:15 or 1215 seconds\n",
      "----------------------------------------\n",
      "Epoch[96/500] Training Loss: 0.384 Reconstruction Loss: 0.256 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 10 Validation Loss: 0.28770846128463745 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:12 or 1212 seconds\n",
      "----------------------------------------\n",
      "Epoch[97/500] Training Loss: 0.382 Reconstruction Loss: 0.253 KL Loss: 0.129\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00097: reducing learning rate of group 0 to 1.8750e-05.\n",
      "Patience: 11 Validation Loss: 0.2865961790084839 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:09 or 1209 seconds\n",
      "----------------------------------------\n",
      "Epoch[98/500] Training Loss: 0.393 Reconstruction Loss: 0.264 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 12 Validation Loss: 0.28629744052886963 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:06 or 1206 seconds\n",
      "----------------------------------------\n",
      "Epoch[99/500] Training Loss: 0.391 Reconstruction Loss: 0.262 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 13 Validation Loss: 0.28732818365097046 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:03 or 1203 seconds\n",
      "----------------------------------------\n",
      "Epoch[100/500] Training Loss: 0.399 Reconstruction Loss: 0.270 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 14 Validation Loss: 0.2869780957698822 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:20:00 or 1200 seconds\n",
      "----------------------------------------\n",
      "Epoch[101/500] Training Loss: 0.396 Reconstruction Loss: 0.266 KL Loss: 0.130\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 15 Validation Loss: 0.28737422823905945 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:57 or 1197 seconds\n",
      "----------------------------------------\n",
      "Epoch[102/500] Training Loss: 0.383 Reconstruction Loss: 0.256 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 16 Validation Loss: 0.2865937352180481 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:54 or 1194 seconds\n",
      "----------------------------------------\n",
      "Epoch[103/500] Training Loss: 0.393 Reconstruction Loss: 0.265 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 17 Validation Loss: 0.28579944372177124 Min validation loss: 0.2842300832271576\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:51 or 1191 seconds\n",
      "----------------------------------------\n",
      "Epoch[104/500] Training Loss: 0.394 Reconstruction Loss: 0.266 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28414076566696167 Min validation loss: 0.28414076566696167\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:26:24 or 1584 seconds\n",
      "----------------------------------------\n",
      "Epoch[105/500] Training Loss: 0.394 Reconstruction Loss: 0.266 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.2841755151748657 Min validation loss: 0.28414076566696167\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:45 or 1185 seconds\n",
      "----------------------------------------\n",
      "Epoch[106/500] Training Loss: 0.393 Reconstruction Loss: 0.265 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.2847566604614258 Min validation loss: 0.28414076566696167\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:42 or 1182 seconds\n",
      "----------------------------------------\n",
      "Epoch[107/500] Training Loss: 0.398 Reconstruction Loss: 0.271 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28376585245132446 Min validation loss: 0.28376585245132446\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:39 or 1179 seconds\n",
      "----------------------------------------\n",
      "Epoch[108/500] Training Loss: 0.380 Reconstruction Loss: 0.254 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28336721658706665 Min validation loss: 0.28336721658706665\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:36 or 1176 seconds\n",
      "----------------------------------------\n",
      "Epoch[109/500] Training Loss: 0.390 Reconstruction Loss: 0.262 KL Loss: 0.128\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2824854254722595 Min validation loss: 0.2824854254722595\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:33 or 1173 seconds\n",
      "----------------------------------------\n",
      "Epoch[110/500] Training Loss: 0.376 Reconstruction Loss: 0.251 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2821596562862396 Min validation loss: 0.2821596562862396\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:30 or 1170 seconds\n",
      "----------------------------------------\n",
      "Epoch[111/500] Training Loss: 0.388 Reconstruction Loss: 0.262 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28083568811416626 Min validation loss: 0.28083568811416626\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:25:56 or 1556 seconds\n",
      "----------------------------------------\n",
      "Epoch[112/500] Training Loss: 0.383 Reconstruction Loss: 0.258 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.28152206540107727 Min validation loss: 0.28083568811416626\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:24 or 1164 seconds\n",
      "----------------------------------------\n",
      "Epoch[113/500] Training Loss: 0.382 Reconstruction Loss: 0.256 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.28039446473121643 Min validation loss: 0.28039446473121643\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:21 or 1161 seconds\n",
      "----------------------------------------\n",
      "Epoch[114/500] Training Loss: 0.389 Reconstruction Loss: 0.262 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.2801523208618164 Min validation loss: 0.2801523208618164\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:18 or 1158 seconds\n",
      "----------------------------------------\n",
      "Epoch[115/500] Training Loss: 0.384 Reconstruction Loss: 0.258 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.27915361523628235 Min validation loss: 0.27915361523628235\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:15 or 1155 seconds\n",
      "----------------------------------------\n",
      "Epoch[116/500] Training Loss: 0.392 Reconstruction Loss: 0.265 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "saving ./Trained_model/model/HDN Muller_best_vae.net\n",
      "Patience: 0 Validation Loss: 0.27818626165390015 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:12 or 1152 seconds\n",
      "----------------------------------------\n",
      "Epoch[117/500] Training Loss: 0.381 Reconstruction Loss: 0.256 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 1 Validation Loss: 0.2794445753097534 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:09 or 1149 seconds\n",
      "----------------------------------------\n",
      "Epoch[118/500] Training Loss: 0.374 Reconstruction Loss: 0.251 KL Loss: 0.123\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 2 Validation Loss: 0.28029918670654297 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:06 or 1146 seconds\n",
      "----------------------------------------\n",
      "Epoch[119/500] Training Loss: 0.387 Reconstruction Loss: 0.262 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 3 Validation Loss: 0.2795323431491852 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:03 or 1143 seconds\n",
      "----------------------------------------\n",
      "Epoch[120/500] Training Loss: 0.387 Reconstruction Loss: 0.262 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 4 Validation Loss: 0.2786157727241516 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:19:00 or 1140 seconds\n",
      "----------------------------------------\n",
      "Epoch[121/500] Training Loss: 0.388 Reconstruction Loss: 0.264 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 5 Validation Loss: 0.27893543243408203 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:57 or 1137 seconds\n",
      "----------------------------------------\n",
      "Epoch[122/500] Training Loss: 0.386 Reconstruction Loss: 0.263 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 6 Validation Loss: 0.27819567918777466 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:54 or 1134 seconds\n",
      "----------------------------------------\n",
      "Epoch[123/500] Training Loss: 0.403 Reconstruction Loss: 0.278 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 7 Validation Loss: 0.27832362055778503 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:51 or 1131 seconds\n",
      "----------------------------------------\n",
      "Epoch[124/500] Training Loss: 0.381 Reconstruction Loss: 0.256 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 8 Validation Loss: 0.2791360020637512 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:48 or 1128 seconds\n",
      "----------------------------------------\n",
      "Epoch[125/500] Training Loss: 0.381 Reconstruction Loss: 0.256 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 9 Validation Loss: 0.27921247482299805 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:45 or 1125 seconds\n",
      "----------------------------------------\n",
      "Epoch[126/500] Training Loss: 0.385 Reconstruction Loss: 0.263 KL Loss: 0.122\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 10 Validation Loss: 0.2796691954135895 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:42 or 1122 seconds\n",
      "----------------------------------------\n",
      "Epoch[127/500] Training Loss: 0.398 Reconstruction Loss: 0.272 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00127: reducing learning rate of group 0 to 9.3750e-06.\n",
      "Patience: 11 Validation Loss: 0.279954731464386 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:39 or 1119 seconds\n",
      "----------------------------------------\n",
      "Epoch[128/500] Training Loss: 0.382 Reconstruction Loss: 0.260 KL Loss: 0.123\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 12 Validation Loss: 0.28043806552886963 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:36 or 1116 seconds\n",
      "----------------------------------------\n",
      "Epoch[129/500] Training Loss: 0.391 Reconstruction Loss: 0.265 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 13 Validation Loss: 0.280437707901001 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:33 or 1113 seconds\n",
      "----------------------------------------\n",
      "Epoch[130/500] Training Loss: 0.393 Reconstruction Loss: 0.267 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 14 Validation Loss: 0.2799719572067261 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:30 or 1110 seconds\n",
      "----------------------------------------\n",
      "Epoch[131/500] Training Loss: 0.392 Reconstruction Loss: 0.267 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 15 Validation Loss: 0.28044751286506653 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:27 or 1107 seconds\n",
      "----------------------------------------\n",
      "Epoch[132/500] Training Loss: 0.396 Reconstruction Loss: 0.269 KL Loss: 0.127\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 16 Validation Loss: 0.27938228845596313 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:24 or 1104 seconds\n",
      "----------------------------------------\n",
      "Epoch[133/500] Training Loss: 0.387 Reconstruction Loss: 0.265 KL Loss: 0.122\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 17 Validation Loss: 0.2805250287055969 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:21 or 1101 seconds\n",
      "----------------------------------------\n",
      "Epoch[134/500] Training Loss: 0.390 Reconstruction Loss: 0.264 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 18 Validation Loss: 0.28024426102638245 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 4seconds\n",
      "Est remaining time: 0:24:24 or 1464 seconds\n",
      "----------------------------------------\n",
      "Epoch[135/500] Training Loss: 0.379 Reconstruction Loss: 0.254 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 19 Validation Loss: 0.28115108609199524 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:15 or 1095 seconds\n",
      "----------------------------------------\n",
      "Epoch[136/500] Training Loss: 0.384 Reconstruction Loss: 0.258 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 20 Validation Loss: 0.281414270401001 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:12 or 1092 seconds\n",
      "----------------------------------------\n",
      "Epoch[137/500] Training Loss: 0.371 Reconstruction Loss: 0.250 KL Loss: 0.121\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 21 Validation Loss: 0.28153669834136963 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:09 or 1089 seconds\n",
      "----------------------------------------\n",
      "Epoch[138/500] Training Loss: 0.387 Reconstruction Loss: 0.263 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Epoch 00138: reducing learning rate of group 0 to 4.6875e-06.\n",
      "Patience: 22 Validation Loss: 0.2809317111968994 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:06 or 1086 seconds\n",
      "----------------------------------------\n",
      "Epoch[139/500] Training Loss: 0.390 Reconstruction Loss: 0.266 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 23 Validation Loss: 0.282382994890213 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:03 or 1083 seconds\n",
      "----------------------------------------\n",
      "Epoch[140/500] Training Loss: 0.384 Reconstruction Loss: 0.258 KL Loss: 0.126\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 24 Validation Loss: 0.28068944811820984 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:18:00 or 1080 seconds\n",
      "----------------------------------------\n",
      "Epoch[141/500] Training Loss: 0.372 Reconstruction Loss: 0.250 KL Loss: 0.122\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 25 Validation Loss: 0.2806113362312317 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:57 or 1077 seconds\n",
      "----------------------------------------\n",
      "Epoch[142/500] Training Loss: 0.391 Reconstruction Loss: 0.267 KL Loss: 0.125\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 26 Validation Loss: 0.2802629768848419 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:54 or 1074 seconds\n",
      "----------------------------------------\n",
      "Epoch[143/500] Training Loss: 0.383 Reconstruction Loss: 0.261 KL Loss: 0.122\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 27 Validation Loss: 0.2805477976799011 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:51 or 1071 seconds\n",
      "----------------------------------------\n",
      "Epoch[144/500] Training Loss: 0.382 Reconstruction Loss: 0.258 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 28 Validation Loss: 0.28052783012390137 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:48 or 1068 seconds\n",
      "----------------------------------------\n",
      "Epoch[145/500] Training Loss: 0.374 Reconstruction Loss: 0.250 KL Loss: 0.124\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 29 Validation Loss: 0.2811911106109619 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:45 or 1065 seconds\n",
      "----------------------------------------\n",
      "Epoch[146/500] Training Loss: 0.375 Reconstruction Loss: 0.252 KL Loss: 0.123\n",
      "saving ./Trained_model/model/HDN Muller_last_vae.net\n",
      "Patience: 30 Validation Loss: 0.2814292311668396 Min validation loss: 0.27818626165390015\n",
      "Time for epoch: 3seconds\n",
      "Est remaining time: 0:17:42 or 1062 seconds\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training.train_network(model=model,lr=lr,max_epochs=max_epochs,steps_per_epoch=steps_per_epoch,directory_path=directory_path,\n",
    "                       train_loader=train_loader,val_loader=val_loader,test_loader=test_loader,\n",
    "                       virtual_batch=virtual_batch,gaussian_noise_std=gaussian_noise_std,\n",
    "                       model_name=model_name,val_loss_patience=30, debug=debug, save_output=save_output, project_name=project, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainHist=np.load(directory_path+\"model/train_loss.npy\")\n",
    "reconHist=np.load(directory_path+\"model/train_reco_loss.npy\")\n",
    "klHist=np.load(directory_path+\"model/train_kl_loss.npy\")\n",
    "valHist=np.load(directory_path+\"model/val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(trainHist,label='training')\n",
    "plt.plot(valHist,label='validation')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(reconHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"reconstruction loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(klHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KL loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LadderVAE(\n",
       "  (first_bottom_up): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): BottomUpDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (top_down_layers): ModuleList(\n",
       "    (0-3): 4 x TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_p): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (merge): MergeLayer(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (skip_connection_merger): SkipConnectionMerger(\n",
       "        (layer): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ResidualGatedBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownLayer(\n",
       "      (deterministic_block): Sequential(\n",
       "        (0): TopDownDeterministicResBlock(\n",
       "          (pre_conv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): TopDownDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stochastic): NormalStochasticBlock2d(\n",
       "        (conv_in_q): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_out): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottom_up_layers): ModuleList(\n",
       "    (0-4): 5 x BottomUpLayer(\n",
       "      (net): Sequential(\n",
       "        (0): BottomUpDeterministicResBlock(\n",
       "          (pre_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): BottomUpDeterministicResBlock(\n",
       "          (res): ResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): ELU(alpha=1.0)\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (3): Dropout2d(p=0.2, inplace=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (5): ELU(alpha=1.0)\n",
       "              (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (7): Dropout2d(p=0.2, inplace=False)\n",
       "              (8): GateLayer2d(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (nonlin): ELU(alpha=1.0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_top_down): Sequential(\n",
       "    (0): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TopDownDeterministicResBlock(\n",
       "      (res): ResidualBlock(\n",
       "        (block): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): Dropout2d(p=0.2, inplace=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): Dropout2d(p=0.2, inplace=False)\n",
       "          (8): GateLayer2d(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (nonlin): ELU(alpha=1.0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (parameter_net): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = \"./Trained_model/\" \n",
    "model = torch.load(directory_path+\"model/HDN Muller_best_vae.net\")\n",
    "model.mode_pred=True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 15.81 GiB total capacity; 12.51 GiB already allocated; 207.94 MiB free; 12.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m range_psnr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(signal[\u001b[39m0\u001b[39m])\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmin(signal[\u001b[39m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(observation\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m----> 8\u001b[0m     img_mmse, samples \u001b[39m=\u001b[39m boilerplate\u001b[39m.\u001b[39;49mpredict(observation[i],num_samples,model,gaussian_noise_std,device,tta)\n\u001b[1;32m      9\u001b[0m     psnr \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mPSNR(signal[\u001b[39m0\u001b[39m], img_mmse, range_psnr)\n\u001b[1;32m     10\u001b[0m     psnrs\u001b[39m.\u001b[39mappend(psnr)\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../boilerplate/boilerplate.py:382\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(img, num_samples, model, gaussian_noise_std, device, tta)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mreturn\u001b[39;00m mmse_back_transformed, samples\n\u001b[1;32m    381\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     img_mmse,samples \u001b[39m=\u001b[39m predict_mmse(img, num_samples, model, gaussian_noise_std, \n\u001b[1;32m    383\u001b[0m                                             device\u001b[39m=\u001b[39;49mdevice, return_samples\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    385\u001b[0m     \u001b[39mreturn\u001b[39;00m img_mmse, samples\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../boilerplate/boilerplate.py:340\u001b[0m, in \u001b[0;36mpredict_mmse\u001b[0;34m(img_n, num_samples, model, gaussian_noise_std, device, return_samples)\u001b[0m\n\u001b[1;32m    337\u001b[0m samples \u001b[39m=\u001b[39m []\n\u001b[1;32m    339\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_samples)):\n\u001b[0;32m--> 340\u001b[0m     sample \u001b[39m=\u001b[39m predict_sample(image_sample, model, gaussian_noise_std, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    341\u001b[0m     samples\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msqueeze(sample))\n\u001b[1;32m    343\u001b[0m img_mmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(samples),axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../boilerplate/boilerplate.py:310\u001b[0m, in \u001b[0;36mpredict_sample\u001b[0;34m(img, model, gaussian_noise_std, device)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_sample\u001b[39m(img, model, gaussian_noise_std, device):\n\u001b[1;32m    298\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[39m    Predicts a sample.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39m    device: GPU device\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     outputs \u001b[39m=\u001b[39m forward_pass(img, img, device, model, gaussian_noise_std)\n\u001b[1;32m    311\u001b[0m     recon \u001b[39m=\u001b[39m outputs[\u001b[39m'\u001b[39m\u001b[39mout_mean\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    312\u001b[0m     recon_denormalized \u001b[39m=\u001b[39m recon\u001b[39m*\u001b[39mmodel\u001b[39m.\u001b[39mdata_std\u001b[39m+\u001b[39mmodel\u001b[39m.\u001b[39mdata_mean\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../boilerplate/boilerplate.py:93\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(x, y, device, model, gaussian_noise_std)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_pass\u001b[39m(x, y, device, model, gaussian_noise_std)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     92\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 93\u001b[0m     model_out \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mmode_pred \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         recons_sep \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmodel_out[\u001b[39m'\u001b[39m\u001b[39mll\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../models/lvae.py:200\u001b[0m, in \u001b[0;36mLadderVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m bu_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottomup_pass(x_pad)\n\u001b[1;32m    199\u001b[0m \u001b[39m# Top-down inference/generation\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m out, td_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtopdown_pass(bu_values)\n\u001b[1;32m    202\u001b[0m \u001b[39m# Restore original image size\u001b[39;00m\n\u001b[1;32m    203\u001b[0m out \u001b[39m=\u001b[39m crop_img_tensor(out, img_size)\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../models/lvae.py:316\u001b[0m, in \u001b[0;36mLadderVAE.topdown_pass\u001b[0;34m(self, bu_values, n_img_prior, mode_layers, constant_layers, forced_latent)\u001b[0m\n\u001b[1;32m    313\u001b[0m skip_input \u001b[39m=\u001b[39m out  \u001b[39m# TODO or out_pre_residual? or both?\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m# Full top-down layer, including sampling and deterministic part\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m out, out_pre_residual, aux \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_down_layers[i](\n\u001b[1;32m    317\u001b[0m     out,\n\u001b[1;32m    318\u001b[0m     skip_connection_input\u001b[39m=\u001b[39;49mskip_input,\n\u001b[1;32m    319\u001b[0m     inference_mode\u001b[39m=\u001b[39;49minference_mode,\n\u001b[1;32m    320\u001b[0m     bu_value\u001b[39m=\u001b[39;49mbu_value,\n\u001b[1;32m    321\u001b[0m     n_img_prior\u001b[39m=\u001b[39;49mn_img_prior,\n\u001b[1;32m    322\u001b[0m     use_mode\u001b[39m=\u001b[39;49muse_mode,\n\u001b[1;32m    323\u001b[0m     force_constant_output\u001b[39m=\u001b[39;49mconstant_out,\n\u001b[1;32m    324\u001b[0m     forced_latent\u001b[39m=\u001b[39;49mforced_latent[i],\n\u001b[1;32m    325\u001b[0m     mode_pred\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode_pred,\n\u001b[1;32m    326\u001b[0m     use_uncond_mode\u001b[39m=\u001b[39;49muse_uncond_mode\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    328\u001b[0m z[i] \u001b[39m=\u001b[39m aux[\u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# sampled variable at this layer (batch, ch, h, w)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m kl[i] \u001b[39m=\u001b[39m aux[\u001b[39m'\u001b[39m\u001b[39mkl_samplewise\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# (batch, )\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../models/lvae_layers.py:181\u001b[0m, in \u001b[0;36mTopDownLayer.forward\u001b[0;34m(self, input_, skip_connection_input, inference_mode, bu_value, n_img_prior, forced_latent, use_mode, force_constant_output, mode_pred, use_uncond_mode)\u001b[0m\n\u001b[1;32m    178\u001b[0m x_pre_residual \u001b[39m=\u001b[39m x\n\u001b[1;32m    180\u001b[0m \u001b[39m# Last top-down block (sequence of residual blocks)\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeterministic_block(x)\n\u001b[1;32m    183\u001b[0m keys \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkl_samplewise\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkl_spatial\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogprob_p\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogprob_q\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    184\u001b[0m data \u001b[39m=\u001b[39m {k: data_stoch[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m keys}\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../models/lvae_layers.py:310\u001b[0m, in \u001b[0;36mResBlockWithResampling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_conv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_conv(x)\n\u001b[0;32m--> 310\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mres(x)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_conv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_conv(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../lib/nn.py:99\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(x) \u001b[39m+\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GIT/HDN/examples/Pixel_Noise/Convallaria/../../../lib/nn.py:122\u001b[0m, in \u001b[0;36mGateLayer2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 122\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m    123\u001b[0m     x, gate \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(x, \u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnonlin(x)  \u001b[39m# TODO remove this?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/maester/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 15.81 GiB total capacity; 12.51 GiB already allocated; 207.94 MiB free; 12.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "signal=np.mean(observation[:,...],axis=0)[np.newaxis,...]\n",
    "gaussian_noise_std = None\n",
    "num_samples = 100 # number of samples used to compute MMSE estimate\n",
    "tta = False # turn on test time augmentation when set to True. It may improve performance at the expense of 8x longer prediction time\n",
    "psnrs = []\n",
    "range_psnr = np.max(signal[0])-np.min(signal[0])\n",
    "for i in range(observation.shape[0]):\n",
    "    img_mmse, samples = boilerplate.predict(observation[i],num_samples,model,gaussian_noise_std,device,tta)\n",
    "    psnr = utils.PSNR(signal[0], img_mmse, range_psnr)\n",
    "    psnrs.append(psnr)\n",
    "    print(\"image:\", i, \"PSNR:\", psnr, \"Mean PSNR:\", np.mean(psnrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
